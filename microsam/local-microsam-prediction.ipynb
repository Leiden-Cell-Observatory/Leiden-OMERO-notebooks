{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction with finetuned model of micro-sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Numpy\n",
    "import numpy as np\n",
    "import datetime\n",
    "# Import Python System Packages\n",
    "import os\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tifffile import imwrite\n",
    "import imageio\n",
    "import shutil\n",
    "import cv2\n",
    "#micro-sam related imports\n",
    "from micro_sam.automatic_segmentation import get_predictor_and_segmenter, automatic_instance_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose a path to \n",
    "os.path.abspath(\n",
    "print(f\"Data directory: {output_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_automatic_instance_segmentation(image, checkpoint_path, model_type=\"vit_b_lm\", device=None):\n",
    "    \"\"\"Automatic Instance Segmentation (AIS) by training an additional instance decoder in SAM.\n",
    "\n",
    "    NOTE: AIS is supported only for `µsam` models.\n",
    "\n",
    "    Args:\n",
    "        image: The input image.\n",
    "        checkpoint_path: The path to stored checkpoints.\n",
    "        model_type: The choice of the `µsam` model.\n",
    "        device: The device to run the model inference.\n",
    "\n",
    "    Returns:\n",
    "        The instance segmentation.\n",
    "    \"\"\"\n",
    "    # Step 1: Get the 'predictor' and 'segmenter' to perform automatic instance segmentation.\n",
    "    predictor, segmenter = get_predictor_and_segmenter(\n",
    "        model_type=model_type, # choice of the Segment Anything model\n",
    "        checkpoint=checkpoint_path,  # overwrite to pass your own finetuned model.\n",
    "        device=device,  # the device to run the model inference.\n",
    "    )\n",
    "\n",
    "    # Step 2: Get the instance segmentation for the given image.\n",
    "    prediction = automatic_instance_segmentation(\n",
    "        predictor=predictor,  # the predictor for the Segment Anything model.\n",
    "        segmenter=segmenter,  # the segmenter class responsible for generating predictions.\n",
    "        input_path=image,\n",
    "        ndim=2,\n",
    "    )\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_label_plots(image,labels):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from IPython.display import display\n",
    "    import stackview\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15,15))\n",
    "\n",
    "    stackview.imshow(image, plot=axs[0], title='image', axes=True)\n",
    "    stackview.imshow(labels, plot=axs[1], title='labels')\n",
    "\n",
    "    stackview.imshow(image, plot=axs[2], continue_drawing=True)\n",
    "    stackview.imshow(labels, plot=axs[2], alpha=0.4, title='image + labels')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def process_omero_prediction_batch(\n",
    "    dataset,\n",
    "    output_folder: str,\n",
    "    model_path: str,\n",
    "    model_type: str = 'vit_l',\n",
    "    model_id: int = None,\n",
    "    batch_size: int = 3,\n",
    "    channel: int = 0,\n",
    "    timepoint: int = 0,\n",
    "    z_slice: int = 0,\n",
    "    show_results: bool = False,\n",
    "    test_mode: bool = False,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    This function processes images from an OMERO dataset using a fine-tuned Segment Anything Model (SAM)\n",
    "    for automatic instance segmentation. It handles batch processing, prediction uploads, and tracking.\n",
    "        dataset: OMERO dataset object containing images to process\n",
    "        output_folder (str): Path to store temporary prediction files\n",
    "        model_path (str): Path to the fine-tuned SAM model checkpoint file\n",
    "        model_type (str, optional): SAM model type to use. Defaults to 'vit_l'\n",
    "        model_id (int, optional): SAM model ID in OMERO. Defaults to None\n",
    "        batch_size (int, optional): Number of images to process in each batch. Defaults to 3\n",
    "        channel (int, optional): Channel index to segment. Defaults to 0\n",
    "        timepoint (int, optional): Timepoint to process. Defaults to 0\n",
    "        z_slice (int, optional): Z-slice index to process. Defaults to 0\n",
    "        show_results (bool, optional): Whether to display results during processing. Defaults to False\n",
    "        test_mode (bool, optional): Whether to run in test mode with user interaction. Defaults to False\n",
    "    Returns:\n",
    "        int: Table ID of the uploaded tracking table in OMERO\n",
    "    \"\"\"\n",
    "    # Setup output directory\n",
    "    output_path = os.path.join(output_folder, \"predictions\")\n",
    "    \n",
    "    # Remove directory if exists and create fresh\n",
    "    if os.path.exists(output_path):\n",
    "        shutil.rmtree(output_path)\n",
    "    os.makedirs(output_path)\n",
    "    \n",
    "    # Get all images from dataset\n",
    "    images_dataset = list(dataset.listChildren())\n",
    "    total_batches = (len(images_dataset) + batch_size - 1) // batch_size\n",
    "\n",
    "    # Create tracking dataframe\n",
    "    df = pd.DataFrame(columns=[\n",
    "        \"image_id\", \"image_name\", \"channel\", \"timepoint\", \n",
    "        \"sam_model\", \"label_id\", \"roi_id\"\n",
    "    ])\n",
    "    \n",
    "    # Process images in batches\n",
    "    for batch_idx in range(total_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, len(images_dataset))\n",
    "        batch_images = images_dataset[start_idx:end_idx]\n",
    "        \n",
    "        # Process each image in batch\n",
    "        for n, image in enumerate(batch_images):\n",
    "            local_n = n\n",
    "            \n",
    "            # Get image plane\n",
    "            pixels = image.getPrimaryPixels()\n",
    "            img = pixels.getPlane(z_slice, channel, timepoint)\n",
    "            print(img.shape)\n",
    "            \n",
    "            # Run automatic instance segmentation\n",
    "            prediction = run_automatic_instance_segmentation(\n",
    "                image=img, \n",
    "                checkpoint_path=model_path,\n",
    "                model_type=model_type,\n",
    "                device='cuda'\n",
    "            )\n",
    "            \n",
    "            # Save prediction\n",
    "            pred_file = os.path.join(output_path, f\"pred_{local_n:05d}.tif\")\n",
    "            imageio.imwrite(pred_file, prediction)\n",
    "            \n",
    "            if show_results:\n",
    "                show_label_plots(img, prediction)\n",
    "\n",
    "            if test_mode:\n",
    "                user_input = input(\"Press Enter to continue, or type 'stop' to halt execution: \")\n",
    "                if user_input.lower() == 'stop':\n",
    "                    raise SystemExit(\"User requested to stop execution\")\n",
    "\n",
    "            # Upload prediction and ROIs\n",
    "            label_id, roi_id = upload_prediction_and_rois(\n",
    "                conn, \n",
    "                image, \n",
    "                pred_file, \n",
    "                z_slice, \n",
    "                channel, \n",
    "                timepoint, \n",
    "                model_type,\n",
    "                model_id\n",
    "            )\n",
    "            \n",
    "            # Update tracking dataframe\n",
    "            new_row = pd.DataFrame([{\n",
    "                \"image_id\": image.getId(),\n",
    "                \"image_name\": image.getName(),\n",
    "                \"channel\": channel,\n",
    "                \"z_slice\": z_slice,\n",
    "                \"timepoint\": timepoint,\n",
    "                \"sam_model\": model_type,\n",
    "                \"model_id\": model_id,\n",
    "                \"label_id\": label_id,\n",
    "                \"roi_id\": roi_id\n",
    "            }])\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "            \n",
    "            # Clean up prediction file\n",
    "            if os.path.exists(pred_file):\n",
    "                os.remove(pred_file)\n",
    "    \n",
    "    # Upload tracking table\n",
    "    table_id = ezomero.post_table(\n",
    "        conn, \n",
    "        object_type=\"Dataset\", \n",
    "        object_id=dataset.getId(), \n",
    "        table=df,\n",
    "        title=\"micro_sam_prediction_data\"\n",
    "    )\n",
    "    \n",
    "    return table_id\n",
    "\n",
    "\n",
    "def mask_to_contour(mask):\n",
    "    \"\"\"Converts a binary mask to a list of ROI coordinates.\n",
    "\n",
    "    Args:\n",
    "        mask (np.ndarray): binary mask\n",
    "\n",
    "    Returns:\n",
    "        list: list of ROI coordinates\n",
    "    \"\"\"\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "def label_to_rois(label_img, z_slice, channel, timepoint):\n",
    "    \"\"\"\n",
    "    Convert a 2D label image to OMERO ROI shapes\n",
    "    \n",
    "    Args:\n",
    "        label_img (np.ndarray): 2D labeled image\n",
    "        z_slice (int): Z-slice index\n",
    "        channel (int): Channel index\n",
    "        timepoint (int): Time point index\n",
    "    \n",
    "    Returns:\n",
    "        list: List of OMERO shape objects\n",
    "    \"\"\"\n",
    "    shapes = []\n",
    "    unique_labels = np.unique(label_img)\n",
    "    \n",
    "    # Skip background (label 0)\n",
    "    for label in unique_labels[1:]:\n",
    "        # Create binary mask for this label\n",
    "        mask = (label_img == label).astype(np.uint8)\n",
    "        \n",
    "        # Get contours\n",
    "        contours = mask_to_contour(mask)\n",
    "        \n",
    "        # Convert each contour to polygon ROI\n",
    "        for contour in contours:\n",
    "            contour = contour[:, 0, :]  # Reshape to (N, 2)\n",
    "            # Create polygon without text parameter\n",
    "            poly = ezomero.rois.Polygon(\n",
    "                points=contour,  # explicitly name the points parameter\n",
    "                z=z_slice,\n",
    "                c=channel,\n",
    "                t=timepoint\n",
    "            )\n",
    "            shapes.append(poly)\n",
    "    \n",
    "    return shapes\n",
    "\n",
    "def upload_prediction_and_rois(conn, image, pred_file, z_slice, channel, timepoint, model_type, model_id):\n",
    "    \"\"\"\n",
    "    Upload prediction map and ROIs for automatically segmented image\n",
    "    \"\"\"\n",
    "    # Upload prediction as attachment\n",
    "    label_id = ezomero.post_file_annotation(\n",
    "        conn,\n",
    "        str(pred_file),\n",
    "        ns='microsam.automatic_prediction',\n",
    "        object_type=\"Image\",\n",
    "        object_id=image.getId(),\n",
    "        description=f'SAM automatic instance segmentation ({model_id}) ({model_type})'\n",
    "    )\n",
    "    \n",
    "    # Create ROIs from prediction\n",
    "    pred_img = imageio.imread(pred_file)\n",
    "    shapes = label_to_rois(pred_img, z_slice, channel, timepoint)\n",
    "    \n",
    "    if shapes:\n",
    "        roi_id = ezomero.post_roi(\n",
    "            conn,\n",
    "            image.getId(),\n",
    "            shapes,\n",
    "            name=f'SAM_automatic_{model_id}_{model_type}',\n",
    "            description='micro_sam.automatic_instance_segmentation'\n",
    "        )\n",
    "    else:\n",
    "        roi_id = None\n",
    "        \n",
    "    return label_id, roi_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = 'C:\\\\Users\\\\mwpaul\\\\micro-sam_models\\\\micro-sam-20250207_095503\\\\models\\\\checkpoints\\\\sam\\\\'\n",
    "model_id = 'micro-sam-20250207_095503'\n",
    "best_checkpoint = os.path.join(model_folder, \"best.pt\")\n",
    "model_type = \"vit_l\"\n",
    "channel = 3\n",
    "batch_size = 1\n",
    "timepoint = 0\n",
    "z_slice = 5\n",
    "table_id = process_omero_prediction_batch(\n",
    "    dataset=dataset,\n",
    "    output_folder=output_directory,\n",
    "    model_path=best_checkpoint,\n",
    "    model_type=model_type,\n",
    "    model_id=model_id,\n",
    "    batch_size=batch_size,\n",
    "    channel=channel,\n",
    "    timepoint=timepoint,\n",
    "    z_slice=z_slice,\n",
    "    test_mode=False,\n",
    "    show_results=False,\n",
    ")\n",
    "print(\"Prediction Table ID:\", table_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micro-sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
