{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning SAM with OMERO data using a batch approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO\n",
    "- make it work for different OMERO data types (single images, plates, etc)\n",
    "- store all annotations into OMERO, see: https://github.com/computational-cell-analytics/micro-sam/issues/445; in series annotator possible to add commit path with prompts, but they get overwritten\n",
    "- clean up the errors and warnings output from napari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "  - To make it easier to run with OMERO and to not expose login and passwords password is stored in .env file (see example .env_example) . Still it is not recommended to save credentials unencrypted hence a better solution will be worked on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OMERO-related imports\n",
    "import omero\n",
    "from omero.gateway import BlitzGateway\n",
    "import ezomero\n",
    "\n",
    "# Scientific computing and image processing\n",
    "import cv2\n",
    "import imageio.v3 as imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# File and system operations\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import zipfile\n",
    "import warnings\n",
    "from tifffile import imwrite\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Micro-SAM and Napari\n",
    "from napari.settings import get_settings\n",
    "from micro_sam.sam_annotator import image_series_annotator, annotator_2d\n",
    "from micro_sam.util import precompute_image_embeddings\n",
    "import napari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup connection with OMERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "conn = BlitzGateway(host=os.environ.get(\"HOST\"), username=os.environ.get(\"USER_NAME\"), passwd=os.environ.get(\"PASSWORD\"), secure=True)\n",
    "connection_status = conn.connect()\n",
    "if connection_status:\n",
    "    print(\"Connected to OMERO Server\")\n",
    "else:\n",
    "    print(\"Connection to OMERO Server Failed\")\n",
    "conn.c.enableKeepAlive(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get info from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = \"dataset\" # \"plate\", \"dataset\", \"image\"\n",
    "data_id = 24143\n",
    "nucl_channel = 0\n",
    "\n",
    "#validate that data_id matches datatype\n",
    "if datatype == \"plate\":\n",
    "    dataset = conn.getObject(\"Plate\", data_id)\n",
    "    print('Plate Name: ', plate.getName())\n",
    "elif datatype == \"dataset\":\n",
    "    dataset = conn.getObject(\"Dataset\", data_id)\n",
    "    print('Dataset Name: ', dataset.getName())\n",
    "elif datatype == \"image\":\n",
    "    dataset = conn.getObject(\"Image\", data_id)\n",
    "    print('Image Name: ', image.getName())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create temporary folder to store training data, this will be uploaded to OMERO later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = os.path.normcase(tempfile.mkdtemp())\n",
    "print('Output Directory: ', output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def zip_directory(source_path, zarr_path, zip_file):\n",
    "    \"\"\"Zip a directory while handling null characters in paths.\"\"\"\n",
    "    for root, dirs, files in os.walk(zarr_path):\n",
    "        for file in files:\n",
    "            try:\n",
    "                # Create paths\n",
    "                full_path = os.path.join(root, file)\n",
    "                rel_path = os.path.relpath(full_path, source_path)\n",
    "                \n",
    "                # Remove null characters while preserving the path structure\n",
    "                safe_full_path = full_path.replace('\\x00', '')\n",
    "                safe_rel_path = rel_path.replace('\\x00', '')\n",
    "                \n",
    "                # Add file to zip if it exists\n",
    "                if os.path.exists(safe_full_path):\n",
    "                    zip_file.write(safe_full_path, safe_rel_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Error processing {file}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "def interleave_arrays(train_images, validate_images):\n",
    "    \"\"\"\n",
    "    Interleave two arrays of images in the pattern: train[0], validate[0], train[1], validate[1], ...\n",
    "    If arrays are of unequal length, remaining elements are appended at the end.\n",
    "    \"\"\"\n",
    "    # Create empty list to store interleaved images\n",
    "    interleaved = []\n",
    "    sequence = []\n",
    "    # Get the length of the longer array\n",
    "    max_len = max(len(train_images), len(validate_images))\n",
    "    \n",
    "    # Interleave the arrays\n",
    "    for i in range(max_len):\n",
    "        # Add train image if available\n",
    "        if i < len(train_images):\n",
    "            interleaved.append(train_images[i])\n",
    "            sequence.append(0)\n",
    "        # Add validate image if available\n",
    "        if i < len(validate_images):\n",
    "            interleaved.append(validate_images[i])\n",
    "            sequence.append(1)\n",
    "    \n",
    "    return np.array(interleaved), np.array(sequence)\n",
    "\n",
    "\n",
    "def mask_to_contour(mask):\n",
    "    \"\"\"Converts a binary mask to a list of ROI coordinates.\n",
    "\n",
    "    Args:\n",
    "        mask (np.ndarray): binary mask\n",
    "\n",
    "    Returns:\n",
    "        list: list of ROI coordinates\n",
    "    \"\"\"\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "def label_to_rois(label_img, z_slice, channel, timepoint):\n",
    "    \"\"\"\n",
    "    Convert a 2D label image to OMERO ROI shapes\n",
    "    \n",
    "    Args:\n",
    "        label_img (np.ndarray): 2D labeled image\n",
    "        z_slice (int): Z-slice index\n",
    "        channel (int): Channel index\n",
    "        timepoint (int): Time point index\n",
    "    \n",
    "    Returns:\n",
    "        list: List of OMERO shape objects\n",
    "    \"\"\"\n",
    "    shapes = []\n",
    "    unique_labels = np.unique(label_img)\n",
    "    \n",
    "    # Skip background (label 0)\n",
    "    for label in unique_labels[1:]:\n",
    "        # Create binary mask for this label\n",
    "        mask = (label_img == label).astype(np.uint8)\n",
    "        \n",
    "        # Get contours\n",
    "        contours = mask_to_contour(mask)\n",
    "        \n",
    "        # Convert each contour to polygon ROI\n",
    "        for contour in contours:\n",
    "            contour = contour[:, 0, :]  # Reshape to (N, 2)\n",
    "            # Create polygon without text parameter\n",
    "            poly = ezomero.rois.Polygon(\n",
    "                points=contour,  # explicitly name the points parameter\n",
    "                z=z_slice,\n",
    "                c=channel,\n",
    "                t=timepoint\n",
    "            )\n",
    "            shapes.append(poly)\n",
    "    \n",
    "    return shapes\n",
    "\n",
    "def upload_rois_and_labels(conn, image, label_file, z_slice, channel, timepoint, model_type):\n",
    "    \"\"\"\n",
    "    Upload both label map and ROIs for a segmented image\n",
    "    \n",
    "    Args:\n",
    "        conn: OMERO connection\n",
    "        image: OMERO image object\n",
    "        label_file: Path to the label image file\n",
    "        z_slice: Z-slice index\n",
    "        channel: Channel index\n",
    "        timepoint: Time point index\n",
    "        model_type: SAM model type used\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (label_id, roi_id)\n",
    "    \"\"\"\n",
    "    # Upload label map as attachment\n",
    "    label_id = ezomero.post_file_annotation(\n",
    "        conn,\n",
    "        str(label_file),\n",
    "        ns='microsam.labelimage',\n",
    "        object_type=\"Image\",\n",
    "        object_id=image.getId(),\n",
    "        description=f'SAM segmentation ({model_type})'\n",
    "    )\n",
    "    \n",
    "    # Create ROIs from label image\n",
    "    label_img = imageio.imread(label_file)\n",
    "    shapes = label_to_rois(label_img, z_slice, channel, timepoint)\n",
    "    \n",
    "    if shapes:  # Only create ROI if shapes were found\n",
    "        roi_id = ezomero.post_roi(\n",
    "            conn,\n",
    "            image.getId(),\n",
    "            shapes,\n",
    "            name=f'SAM_{model_type}',\n",
    "            description=f'Segmentation using SAM model {model_type}'\n",
    "        )\n",
    "    else:\n",
    "        roi_id = None\n",
    "        \n",
    "    return label_id, roi_id\n",
    "\n",
    "def process_omero_batch(\n",
    "    dataset: int = None,\n",
    "    datatype: str = \"dataset\",\n",
    "    output_folder: str = None,\n",
    "    model_type: str = 'vit_l',\n",
    "    batch_size: int = 3,\n",
    "    channel: int = 0,\n",
    "    timepoint: int = 0,\n",
    "    z_slice: int = 0,\n",
    "    segment_all: bool = True,\n",
    "    train_n: int = 3,\n",
    "    validate_n: int = 3,\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    Process OMERO dataset in batches for SAM segmentation and upload results back to OMERO\n",
    "    \n",
    "    Args:\n",
    "        dataset: OMERO dataset object\n",
    "        output_folder: Path to store temporary files\n",
    "        model_type: SAM model type\n",
    "        batch_size: Number of images to process at once\n",
    "        channel: Channel to segment\n",
    "        timepoint: Timepoint to process\n",
    "        z_slice: Z-slice to process\n",
    "        segment_all: segment all images in the dataset or only \n",
    "        \n",
    "    \"\"\"\n",
    "    # Setup output directories\n",
    "    output_path = os.path.join(output_folder, \"output\")\n",
    "    embed_path = os.path.join(output_folder, \"embed\")\n",
    "    \n",
    "    # Remove directories if they exist\n",
    "    if os.path.exists(output_path):\n",
    "        shutil.rmtree(output_path)\n",
    "    if os.path.exists(embed_path):\n",
    "        shutil.rmtree(embed_path)\n",
    "        \n",
    "    # Create fresh directories\n",
    "    os.makedirs(output_path)\n",
    "    os.makedirs(embed_path)\n",
    "    # Get image IDs based on datatype\n",
    "    if datatype == \"plate\":\n",
    "        images_dataset_ids = ezomero.get_image_ids(conn, plate=data_id)\n",
    "    elif datatype == \"dataset\":\n",
    "        images_dataset_ids = ezomero.get_image_ids(conn, dataset=data_id)\n",
    "    elif datatype == \"image\":\n",
    "        images_dataset_ids = [dataset]\n",
    "    elif datatype == \"project\":\n",
    "        images_dataset_ids = ezomero.get_image_ids(conn, project=data_id)\n",
    "\n",
    "    if segment_all:\n",
    "        selected_image_ids = images_dataset_ids\n",
    "    else:\n",
    "        if len(images_dataset_ids) < train_n + validate_n:\n",
    "            print(\"Not enough images in dataset for training and validation\")\n",
    "            assert False\n",
    "        \n",
    "        # Select IDs for training and validation\n",
    "        train_ids = np.random.choice(images_dataset_ids, train_n, replace=False)\n",
    "        validate_ids = np.random.choice([x for x in images_dataset_ids if x not in train_ids], validate_n, replace=False)\n",
    "        combined_image_ids, _ = interleave_arrays(train_ids, validate_ids)\n",
    "        selected_image_ids = combined_image_ids\n",
    "    if batch_size >  len(selected_image_ids):\n",
    "        batch_size = len(selected_image_ids)\n",
    "        total_batches = 1\n",
    "    else:\n",
    "        total_batches = (len(selected_image_ids) + batch_size - 1) // batch_size\n",
    "    df = pd.DataFrame(columns=[\n",
    "        \"image_id\", \"image_name\", \"train\", \"validate\", \n",
    "        \"channel\", \"timepoint\", \"sam_model\", \"embed_id\", \"label_id\", \"roi_id\"\n",
    "    ])\n",
    "\n",
    "    # Process images in batches\n",
    "    print(f\"\\nStarting processing of {len(selected_image_ids)} images in batches of {batch_size}\")\n",
    "    for batch_idx in range(total_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, len(selected_image_ids))\n",
    "        batch_image_ids = selected_image_ids[start_idx:end_idx]\n",
    "            \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Processing batch {batch_idx + 1} of {total_batches}\")\n",
    "        print(f\"Current batch contains {len(batch_image_ids)} images\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Load batch images only when needed\n",
    "        print(\"Loading images from OMERO...\")\n",
    "        batch_images = [conn.getObject(\"Image\", id) for id in batch_image_ids]\n",
    "        images = []\n",
    "        for image in batch_images:\n",
    "            pixels = image.getPrimaryPixels()\n",
    "            img = pixels.getPlane(z_slice, channel, timepoint)\n",
    "            images.append(img)\n",
    "        \n",
    "        # Process batch with SAM\n",
    "        print(\"\\nOpening napari viewer for segmentation...\")\n",
    "        print(\"Please complete your annotations and close the viewer when done\")\n",
    "        viewer = napari.Viewer()\n",
    "        image_series_annotator(\n",
    "            images, \n",
    "            model_type=model_type,\n",
    "            viewer=viewer,\n",
    "            embedding_path=os.path.join(output_folder, \"embed\"),\n",
    "            output_folder=os.path.join(output_folder, \"output\")\n",
    "        )\n",
    "        \n",
    "        napari.run()\n",
    "        print(\"Done annotating batch, uploading to OMERO now\")\n",
    "        # Upload results for batch\n",
    "        print(\"\\nUploading results to OMERO...\")\n",
    "        for n, image in enumerate(batch_images):\n",
    "            local_n = n\n",
    "            global_n = start_idx + n\n",
    "            \n",
    "            # Upload embedding\n",
    "            embed_zarr = f\"embedding_{local_n:05d}.zarr\"\n",
    "            embed_path = os.path.join(output_folder, \"embed\")\n",
    "            zip_path = os.path.join(output_folder, \"embed\", f\"embedding_{local_n:05d}.zip\")\n",
    "            \n",
    "            with zipfile.ZipFile(zip_path, 'w') as zip_file:\n",
    "                zip_directory(embed_path, embed_zarr, zip_file)\n",
    "            \n",
    "            embed_id = ezomero.post_file_annotation(\n",
    "                conn,\n",
    "                str(zip_path),\n",
    "                ns='microsam.embeddings',\n",
    "                object_type=\"Image\",\n",
    "                object_id=image.getId(),\n",
    "                description=f'SAM embedding ({model_type})'\n",
    "            )\n",
    "            \n",
    "            # Upload labels and ROIs\n",
    "            label_file = os.path.join(output_folder, \"output\", f\"seg_{local_n:05d}.tif\")\n",
    "            label_id, roi_id = upload_rois_and_labels(\n",
    "                conn, \n",
    "                image, \n",
    "                label_file, \n",
    "                z_slice, \n",
    "                channel, \n",
    "                timepoint, \n",
    "                model_type\n",
    "            )\n",
    "            \n",
    "            # Update tracking dataframe\n",
    "            new_row = pd.DataFrame([{\n",
    "                \"image_id\": image.getId(),\n",
    "                \"image_name\": image.getName(),\n",
    "                \"train\": global_n % 2 == 0,\n",
    "                \"validate\": global_n % 2 == 1,\n",
    "                \"channel\": channel,\n",
    "                \"z_slice\": z_slice,\n",
    "                \"timepoint\": timepoint,\n",
    "                \"sam_model\": model_type,\n",
    "                \"embed_id\": embed_id,\n",
    "                \"label_id\": label_id,\n",
    "                \"roi_id\": roi_id\n",
    "            }])\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "        \n",
    "        # Clean up batch files\n",
    "        print(\"Cleaning up temporary files...\")\n",
    "        for n in range(batch_size):  # Use local indexing for cleanup\n",
    "            embed_zip = os.path.join(output_folder, \"embed\", f\"embedding_{n:05d}.zip\")\n",
    "            embed_zarr = os.path.join(output_folder, \"embed\", f\"embedding_{n:05d}.zarr\")\n",
    "            seg_file = os.path.join(output_folder, \"output\", f\"seg_{n:05d}.tif\")\n",
    "            \n",
    "            if os.path.exists(embed_zip):\n",
    "                os.remove(embed_zip)\n",
    "            if os.path.exists(embed_zarr):\n",
    "                shutil.rmtree(embed_zarr)\n",
    "            if os.path.exists(seg_file):\n",
    "                os.remove(seg_file)\n",
    "        print(f\"\\nCompleted batch {batch_idx + 1}\")\n",
    "\n",
    "    # Upload final tracking table\n",
    "    table_id = ezomero.post_table(\n",
    "        conn, \n",
    "        object_type=\"Dataset\", \n",
    "        object_id=dataset.getId(), \n",
    "        table=df,\n",
    "        title=\"micro_sam_training_data\"\n",
    "    )\n",
    "    print(\"\\nAll batches processed successfully!\")\n",
    "    print(f\"Created table with ID: {table_id}\")\n",
    "    return table_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images from OMERO and open in napari with micro-sam annotator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running segmentation in batch\n",
    "\n",
    "Note: some warnings from napari are expected in the output here, generally not a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##imput parameters\n",
    "model_type = 'vit_b'\n",
    "segment_all = False\n",
    "train_n = 20   \n",
    "validate_n = 20\n",
    "channel = 3 #which channel to segment starting from 0\n",
    "timepoint = 0\n",
    "z_slice = 4 #for now pick one slice but TODO add option to pick multiple slices by giving a list of z slices, or random slices\n",
    "batch_size = 10 # the number of images to process at once in napari\n",
    "\n",
    "#set napari settings\n",
    "settings = get_settings()\n",
    "settings.application.ipy_interactive = False\n",
    "\n",
    "# Usage\n",
    "if datatype == \"dataset\":\n",
    "    settings = get_settings()\n",
    "    settings.application.ipy_interactive = False\n",
    "    \n",
    "    table_id = process_omero_batch(\n",
    "        dataset=dataset,\n",
    "        output_folder=output_directory,\n",
    "        model_type=model_type,\n",
    "        batch_size=batch_size,\n",
    "        channel=channel,\n",
    "        timepoint=timepoint,\n",
    "        z_slice=z_slice,\n",
    "        segment_all=segment_all,\n",
    "        train_n=train_n,\n",
    "        validate_n=validate_n,\n",
    "    )\n",
    "    print(\"Table ID:\", table_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micro-sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
