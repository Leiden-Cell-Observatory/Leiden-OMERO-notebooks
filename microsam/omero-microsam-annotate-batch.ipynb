{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning SAM with OMERO data using a batch approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "- Supports multiple OMERO data types (single images, datasets, projects, plates, and screens)\n",
    "- Batch processing with micro-SAM for segmentation\n",
    "- Stores all annotations in OMERO as ROIs and attachments\n",
    "- Uses dask for lazy loading of images for better memory management\n",
    "- Supports 3D volumetric segmentation for z-stacks\n",
    "\n",
    "### TODOs\n",
    "- Store all annotations into OMERO, see: https://github.com/computational-cell-analytics/micro-sam/issues/445; in series annotator possible to add commit path with prompts, but they get overwritten\n",
    "- Clean up the errors and warnings output from napari\n",
    "- Improve ROI creation for 3D volumes to better represent volumetric masks in OMERO\n",
    "- Work with Dask arrays directly in micro-sam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "  - To make it easier to run with OMERO and to not expose login and passwords password is stored in .env file (see example .env_example) . Still it is not recommended to save credentials unencrypted hence a better solution will be worked on.\n",
    "  - This notebook supports processing images from various OMERO container types: images, datasets, projects, plates, and screens.\n",
    "  - Specify the container type in the `datatype` variable and the container ID in the `data_id` variable.\n",
    "  - You can choose to segment all images in the container or select a random subset for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OMERO-related imports\n",
    "import omero\n",
    "from omero.gateway import BlitzGateway\n",
    "import ezomero\n",
    "\n",
    "# Scientific computing and image processing\n",
    "import cv2\n",
    "import imageio.v3 as imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# File and system operations\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import zipfile\n",
    "import warnings\n",
    "from tifffile import imwrite, imread\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Dask and Zarr for lazy loading and processing\n",
    "import dask\n",
    "import dask.array as da\n",
    "import zarr\n",
    "\n",
    "# Micro-SAM and Napari\n",
    "from napari.settings import get_settings\n",
    "from micro_sam.sam_annotator import image_series_annotator, annotator_2d\n",
    "from micro_sam.util import precompute_image_embeddings\n",
    "import napari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup connection with OMERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "conn = BlitzGateway(host=os.environ.get(\"HOST\"), username=os.environ.get(\"USER_NAME\"), passwd=os.environ.get(\"PASSWORD\"), group=os.environ.get(\"GROUP\"), secure=True)\n",
    "connection_status = conn.connect()\n",
    "if connection_status:\n",
    "    print(\"Connected to OMERO Server\")\n",
    "else:\n",
    "    print(\"Connection to OMERO Server Failed\")\n",
    "conn.c.enableKeepAlive(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get info from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = \"dataset\" # \"screen\", \"plate\", \"project\", \"dataset\", \"image\"\n",
    "data_id = 1112\n",
    "nucl_channel = 0\n",
    "\n",
    "def print_object_details(conn, obj, datatype):\n",
    "    \"\"\"Print detailed information about OMERO objects\"\"\"\n",
    "    print(f\"\\n{datatype.capitalize()} Details:\")\n",
    "    print(f\"- Name: {obj.getName()}\")\n",
    "    print(f\"- ID: {obj.getId()}\")\n",
    "    print(f\"- Owner: {obj.getOwner().getFullName()}\")\n",
    "    print(f\"- Group: {obj.getDetails().getGroup().getName()}\")\n",
    "    \n",
    "    if datatype == \"project\":\n",
    "        datasets = list(obj.listChildren())\n",
    "        dataset_count = len(datasets)\n",
    "        total_images = sum(len(list(ds.listChildren())) for ds in datasets)\n",
    "        print(f\"- Number of datasets: {dataset_count}\")\n",
    "        print(f\"- Total images: {total_images}\")\n",
    "        \n",
    "    elif datatype == \"plate\":\n",
    "        wells = list(obj.listChildren())\n",
    "        well_count = len(wells)\n",
    "        print(f\"- Number of wells: {well_count}\")\n",
    "        \n",
    "    elif datatype == \"dataset\":\n",
    "        images = list(obj.listChildren())\n",
    "        image_count = len(images)\n",
    "        # Get project info if dataset is in a project\n",
    "        projects = obj.getParent()\n",
    "        if projects:\n",
    "            print(f\"- Project: {projects.getName()} (ID: {projects.getId()})\")\n",
    "        else:\n",
    "            print(\"- Project: None (orphaned dataset)\")\n",
    "        print(f\"- Number of images: {image_count}\")\n",
    "        \n",
    "    elif datatype == \"image\":\n",
    "        size_x = obj.getSizeX()\n",
    "        size_y = obj.getSizeY()\n",
    "        size_z = obj.getSizeZ()\n",
    "        size_c = obj.getSizeC()\n",
    "        size_t = obj.getSizeT()\n",
    "        # Get dataset info if image is in a dataset\n",
    "        datasets = obj.getParent()\n",
    "        if datasets:\n",
    "            print(f\"- Dataset: {datasets.getName()} (ID: {datasets.getId()})\")\n",
    "            # Get project info if dataset is in a project\n",
    "            projects = datasets.getParent()\n",
    "            if projects:\n",
    "                print(f\"- Project: {projects.getName()} (ID: {projects.getId()})\")\n",
    "        else:\n",
    "            print(\"- Dataset: None (orphaned image)\")\n",
    "        print(f\"- Dimensions: {size_x}x{size_y}\")\n",
    "        print(f\"- Z-stack: {size_z}\")\n",
    "        print(f\"- Channels: {size_c}\")\n",
    "        print(f\"- Timepoints: {size_t}\")\n",
    "\n",
    "# Validate that data_id matches datatype and print details\n",
    "if datatype == \"project\":\n",
    "    project = conn.getObject(\"Project\", data_id)\n",
    "    if project is None:\n",
    "        raise ValueError(f\"Project with ID {data_id} not found\")\n",
    "    print_object_details(conn, project, \"project\")\n",
    "    \n",
    "elif datatype == \"plate\":\n",
    "    plate = conn.getObject(\"Plate\", data_id)\n",
    "    if plate is None:\n",
    "        raise ValueError(f\"Plate with ID {data_id} not found\")\n",
    "    print_object_details(conn, plate, \"plate\")\n",
    "    \n",
    "elif datatype == \"dataset\":\n",
    "    dataset = conn.getObject(\"Dataset\", data_id)\n",
    "    if dataset is None:\n",
    "        raise ValueError(f\"Dataset with ID {data_id} not found\")\n",
    "    print_object_details(conn, dataset, \"dataset\")\n",
    "    \n",
    "elif datatype == \"image\":\n",
    "    image = conn.getObject(\"Image\", data_id)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Image with ID {data_id} not found\")\n",
    "    print_object_details(conn, image, \"image\")\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Invalid datatype specified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create temporary folder to store training data, this will be uploaded to OMERO later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = os.path.normcase(tempfile.mkdtemp())\n",
    "print('Output Directory: ', output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_directory(source_path, zarr_path, zip_file):\n",
    "    \"\"\"Zip a directory while handling null characters in paths.\"\"\"\n",
    "    for root, dirs, files in os.walk(zarr_path):\n",
    "        for file in files:\n",
    "            try:\n",
    "                # Create paths\n",
    "                full_path = os.path.join(root, file)\n",
    "                rel_path = os.path.relpath(full_path, source_path)\n",
    "                \n",
    "                # Remove null characters while preserving the path structure\n",
    "                safe_full_path = full_path.replace('\\x00', '')\n",
    "                safe_rel_path = rel_path.replace('\\x00', '')\n",
    "                \n",
    "                # Add file to zip if it exists\n",
    "                if os.path.exists(safe_full_path):\n",
    "                    zip_file.write(safe_full_path, safe_rel_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Error processing {file}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "def interleave_arrays(train_images, validate_images):\n",
    "    \"\"\"\n",
    "    Interleave two arrays of images in the pattern: train[0], validate[0], train[1], validate[1], ...\n",
    "    If arrays are of unequal length, remaining elements are appended at the end.\n",
    "    \"\"\"\n",
    "    # Create empty list to store interleaved images\n",
    "    interleaved = []\n",
    "    sequence = []\n",
    "    # Get the length of the longer array\n",
    "    max_len = max(len(train_images), len(validate_images))\n",
    "    \n",
    "    # Interleave the arrays\n",
    "    for i in range(max_len):\n",
    "        # Add train image if available\n",
    "        if i < len(train_images):\n",
    "            interleaved.append(train_images[i])\n",
    "            sequence.append(0)\n",
    "        # Add validate image if available\n",
    "        if i < len(validate_images):\n",
    "            interleaved.append(validate_images[i])\n",
    "            sequence.append(1)\n",
    "    \n",
    "    return np.array(interleaved), np.array(sequence)\n",
    "\n",
    "def mask_to_contour(mask):\n",
    "    \"\"\"Converts a binary mask to a list of ROI coordinates.\n",
    "\n",
    "    Args:\n",
    "        mask (np.ndarray): binary mask\n",
    "\n",
    "    Returns:\n",
    "        list: list of ROI coordinates\n",
    "    \"\"\"\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "def label_to_rois(label_img, z_slice, channel, timepoint, model_type, is_volumetric=False):\n",
    "    \"\"\"\n",
    "    Convert a 2D or 3D label image to OMERO ROI shapes\n",
    "    \n",
    "    Args:\n",
    "        label_img (np.ndarray): 2D labeled image or 3D labeled stack\n",
    "        z_slice (int or list): Z-slice index or list/range of Z indices\n",
    "        channel (int): Channel index\n",
    "        timepoint (int): Time point index\n",
    "        model_type (str): SAM model type used\n",
    "        is_volumetric (bool): Whether the label image is 3D volumetric data\n",
    "    \n",
    "    Returns:\n",
    "        list: List of OMERO shape objects\n",
    "    \"\"\"\n",
    "    shapes = []\n",
    "    \n",
    "    if is_volumetric and label_img.ndim > 2:\n",
    "        # 3D volumetric data - process each z slice\n",
    "        for z_index, z_plane in enumerate(label_img):\n",
    "            # If z_slice is a range or list, use the actual z-index from that range\n",
    "            if isinstance(z_slice, (range, list)):\n",
    "                actual_z = z_slice[z_index] if z_index < len(z_slice) else z_slice[0] + z_index\n",
    "            else:\n",
    "                actual_z = z_slice + z_index  # Assume z_slice is the starting index\n",
    "                \n",
    "            print(f\"Processing volumetric ROIs for z-slice {actual_z}\")\n",
    "            shapes.extend(process_label_plane(z_plane, actual_z, channel, timepoint, model_type))\n",
    "    else:\n",
    "        # 2D data - process single plane\n",
    "        shapes.extend(process_label_plane(label_img, z_slice, channel, timepoint, model_type))\n",
    "    \n",
    "    return shapes\n",
    "\n",
    "def process_label_plane(label_plane, z_slice, channel, timepoint, model_type):\n",
    "    \"\"\"Process a single 2D label plane to generate OMERO shapes\"\"\"\n",
    "    shapes = []\n",
    "    unique_labels = np.unique(label_plane)\n",
    "    \n",
    "    # Skip background (label 0)\n",
    "    for label in unique_labels[1:]:\n",
    "        # Create binary mask for this label\n",
    "        mask = (label_plane == label).astype(np.uint8)\n",
    "        \n",
    "        # Get contours\n",
    "        contours = mask_to_contour(mask)\n",
    "        \n",
    "        # Convert each contour to polygon ROI\n",
    "        for contour in contours:\n",
    "            contour = contour[:, 0, :]  # Reshape to (N, 2)\n",
    "            # Create polygon without text parameter\n",
    "            poly = ezomero.rois.Polygon(\n",
    "                points=contour,  # explicitly name the points parameter\n",
    "                z=z_slice,\n",
    "                c=channel,\n",
    "                t=timepoint,\n",
    "                label=f'micro_sam.{\"volumetric\" if z_slice > 0 else \"manual\"}_instance_segmentation.{model_type}'\n",
    "            )\n",
    "            shapes.append(poly)\n",
    "    \n",
    "    return shapes\n",
    "\n",
    "#TODO merge these functions to a source file with functions for processing OMERO data\n",
    "def upload_rois_and_labels(conn, image, label_file, z_slice, channel, timepoint, model_type, is_volumetric=False):\n",
    "    \"\"\"\n",
    "    Upload both label map and ROIs for a segmented image\n",
    "    \n",
    "    Args:\n",
    "        conn: OMERO connection\n",
    "        image: OMERO image object\n",
    "        label_file: Path to the label image file\n",
    "        z_slice: Z-slice index or range of indices\n",
    "        channel: Channel index\n",
    "        timepoint: Time point index\n",
    "        model_type: SAM model type used\n",
    "        is_volumetric: Whether the data is 3D volumetric\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (label_id, roi_id)\n",
    "    \"\"\"\n",
    "    # Upload label map as attachment\n",
    "    label_id = ezomero.post_file_annotation(\n",
    "        conn,\n",
    "        str(label_file),\n",
    "        ns='microsam.labelimage',\n",
    "        object_type=\"Image\",\n",
    "        object_id=image.getId(),\n",
    "        description=f'SAM {\"volumetric\" if is_volumetric else \"manual\"} segmentation ({model_type})'\n",
    "    )\n",
    "    \n",
    "    # Create ROIs from label image\n",
    "    label_img = imageio.imread(label_file)\n",
    "    shapes = label_to_rois(label_img, z_slice, channel, timepoint, model_type, is_volumetric)\n",
    "    \n",
    "    if shapes:  # Only create ROI if shapes were found\n",
    "        roi_id = ezomero.post_roi(\n",
    "            conn,\n",
    "            image.getId(),\n",
    "            shapes,\n",
    "            name=f'SAM_{model_type}{\"_3D\" if is_volumetric else \"\"}',\n",
    "            description=f'micro_sam.{\"volumetric\" if is_volumetric else \"manual\"}_instance_segmentation.{model_type}'\n",
    "        )\n",
    "    else:\n",
    "        roi_id = None\n",
    "        \n",
    "    return label_id, roi_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_from_container(conn, datatype, container_id):\n",
    "    \"\"\"\n",
    "    Extract all images from a given OMERO container (Project, Dataset, Plate, Screen)\n",
    "    \n",
    "    Args:\n",
    "        conn: OMERO connection\n",
    "        datatype: Type of container ('project', 'dataset', 'plate', 'screen', 'image')\n",
    "        container_id: ID of the container\n",
    "        \n",
    "    Returns:\n",
    "        list: List of OMERO image objects\n",
    "        str: Description of the source (for tracking)\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    source_desc = \"\"\n",
    "    \n",
    "    if datatype == \"image\":\n",
    "        image = conn.getObject(\"Image\", container_id)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Image with ID {container_id} not found\")\n",
    "        images = [image]\n",
    "        source_desc = f\"Image: {image.getName()} (ID: {container_id})\"\n",
    "    \n",
    "    elif datatype == \"dataset\":\n",
    "        dataset = conn.getObject(\"Dataset\", container_id)\n",
    "        if dataset is None:\n",
    "            raise ValueError(f\"Dataset with ID {container_id} not found\")\n",
    "        images = list(dataset.listChildren())\n",
    "        source_desc = f\"Dataset: {dataset.getName()} (ID: {container_id})\"\n",
    "    \n",
    "    elif datatype == \"project\":\n",
    "        project = conn.getObject(\"Project\", container_id)\n",
    "        if project is None:\n",
    "            raise ValueError(f\"Project with ID {container_id} not found\")\n",
    "        # Get all datasets in the project\n",
    "        for dataset in project.listChildren():\n",
    "            # Get all images in each dataset\n",
    "            for image in dataset.listChildren():\n",
    "                images.append(image)\n",
    "        source_desc = f\"Project: {project.getName()} (ID: {container_id})\"\n",
    "    \n",
    "    elif datatype == \"plate\":\n",
    "        plate = conn.getObject(\"Plate\", container_id)\n",
    "        if plate is None:\n",
    "            raise ValueError(f\"Plate with ID {container_id} not found\")\n",
    "        # Get all wells in the plate\n",
    "        for well in plate.listChildren():\n",
    "            # Get all images (fields) in each well\n",
    "            for wellSample in well.listChildren():\n",
    "                images.append(wellSample.getImage())\n",
    "        source_desc = f\"Plate: {plate.getName()} (ID: {container_id})\"\n",
    "    \n",
    "    elif datatype == \"screen\":\n",
    "        screen = conn.getObject(\"Screen\", container_id)\n",
    "        if screen is None:\n",
    "            raise ValueError(f\"Screen with ID {container_id} not found\")\n",
    "        # Get all plates in the screen\n",
    "        for plate in screen.listChildren():\n",
    "            # Get all wells in each plate\n",
    "            for well in plate.listChildren():\n",
    "                # Get all images (fields) in each well\n",
    "                for wellSample in well.listChildren():\n",
    "                    images.append(wellSample.getImage())\n",
    "        source_desc = f\"Screen: {screen.getName()} (ID: {container_id})\"\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported datatype: {datatype}\")\n",
    "    \n",
    "    print(f\"Found {len(images)} images from {source_desc}\")\n",
    "    return images, source_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask Lazy Loading Functions for OMERO Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dask_image(conn, image_id, z_slice=None, timepoint=None, channel=None, three_d=False):\n",
    "    \"\"\"\n",
    "    Get a dask array representation of an OMERO image for lazy loading\n",
    "    \n",
    "    Args:\n",
    "        conn: OMERO connection\n",
    "        image_id: ID of image to load\n",
    "        z_slice: Optional specific Z slice to load (int or list)\n",
    "        timepoint: Optional specific timepoint to load (int or list)\n",
    "        channel: Optional specific channel to load (int or list)\n",
    "        three_d: Whether to load a 3D volume (all z-slices) instead of a single slice\n",
    "    \n",
    "    Returns:\n",
    "        dask array representation of image\n",
    "    \"\"\"\n",
    "    image = conn.getObject(\"Image\", image_id)\n",
    "    pixels = image.getPrimaryPixels()\n",
    "    \n",
    "    # Get image dimensions\n",
    "    size_z = image.getSizeZ()\n",
    "    size_c = image.getSizeC()\n",
    "    size_t = image.getSizeT()\n",
    "    size_y = image.getSizeY()\n",
    "    size_x = image.getSizeX()\n",
    "    \n",
    "    # Define specific dimensions to load if provided\n",
    "    # If three_d is True, we want all z-slices, otherwise use the provided z_slice\n",
    "    if three_d:\n",
    "        z_range = range(size_z)  # Load all z-slices for 3D\n",
    "    else:\n",
    "        z_range = [z_slice] if isinstance(z_slice, int) else (range(size_z) if z_slice is None else z_slice)\n",
    "    \n",
    "    t_range = [timepoint] if isinstance(timepoint, int) else (range(size_t) if timepoint is None else timepoint)\n",
    "    c_range = [channel] if isinstance(channel, int) else (range(size_c) if channel is None else channel)\n",
    "    \n",
    "    # Create empty dict to store delayed objects\n",
    "    delayed_planes = {}\n",
    "    \n",
    "    print(f\"Creating dask array for image {image_id} with lazy loading\")\n",
    "    print(f\"Dimensions: Z={len(z_range)}, C={len(c_range)}, T={len(t_range)}, Y={size_y}, X={size_x}\")\n",
    "    print(f\"3D mode: {three_d}\")\n",
    "    \n",
    "    # Create lazy loading function\n",
    "    @dask.delayed\n",
    "    def get_plane(z, c, t):\n",
    "        print(f\"Loading plane: Z={z}, C={c}, T={t}\")\n",
    "        return pixels.getPlane(z, c, t)\n",
    "    \n",
    "    # Build dask arrays\n",
    "    arrays = []\n",
    "    for t in t_range:\n",
    "        t_arrays = []\n",
    "        for z in z_range:\n",
    "            z_arrays = []\n",
    "            for c in c_range:\n",
    "                # Create a key for this plane\n",
    "                key = (z, c, t)\n",
    "                \n",
    "                # Check if we've already created this delayed object\n",
    "                if key not in delayed_planes:\n",
    "                    # Create a delayed object for this plane\n",
    "                    delayed_plane = get_plane(z, c, t)\n",
    "                    delayed_planes[key] = delayed_plane\n",
    "                else:\n",
    "                    delayed_plane = delayed_planes[key]\n",
    "                \n",
    "                # Convert to dask array with known shape and dtype\n",
    "                shape = (size_y, size_x)\n",
    "                dtype = np.uint16  # Most OMERO images use 16-bit\n",
    "                dask_plane = da.from_delayed(delayed_plane, shape=shape, dtype=dtype)\n",
    "                z_arrays.append(dask_plane)\n",
    "            if z_arrays:\n",
    "                # Stack channels for this z position\n",
    "                t_arrays.append(da.stack(z_arrays))\n",
    "        if t_arrays:\n",
    "            # Stack z-planes for this timepoint\n",
    "            arrays.append(da.stack(t_arrays))\n",
    "    \n",
    "    if arrays:\n",
    "        # Stack all timepoints\n",
    "        return da.stack(arrays)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def store_annotations_in_zarr(mask_data, output_folder, image_num):\n",
    "    \"\"\"\n",
    "    Store annotation masks in zarr format for efficient access\n",
    "    \n",
    "    Args:\n",
    "        mask_data: Numpy array with mask data\n",
    "        output_folder: Base folder to store zarr data\n",
    "        image_num: Image number/identifier\n",
    "        \n",
    "    Returns:\n",
    "        path: Path to the zarr store\n",
    "    \"\"\"\n",
    "    # Create zarr directory if it doesn't exist\n",
    "    zarr_dir = os.path.join(output_folder, \"annotations\")\n",
    "    os.makedirs(zarr_dir, exist_ok=True)\n",
    "    \n",
    "    # Create zarr filename\n",
    "    zarr_path = os.path.join(zarr_dir, f\"annotation_{image_num:05d}.zarr\")\n",
    "    \n",
    "    # Remove existing zarr store if it exists\n",
    "    if os.path.exists(zarr_path):\n",
    "        shutil.rmtree(zarr_path)\n",
    "        \n",
    "    # Create zarr array from mask data\n",
    "    z = zarr.open(zarr_path, mode='w')\n",
    "    z.create_dataset('masks', data=mask_data, chunks=(256, 256))\n",
    "    \n",
    "    # Return path to zarr store\n",
    "    return zarr_path\n",
    "\n",
    "def zarr_to_tiff(zarr_path, output_tiff_path):\n",
    "    \"\"\"\n",
    "    Convert zarr store to TIFF file for OMERO upload\n",
    "    \n",
    "    Args:\n",
    "        zarr_path: Path to zarr store\n",
    "        output_tiff_path: Path to save TIFF file\n",
    "        \n",
    "    Returns:\n",
    "        output_tiff_path: Path to saved TIFF file\n",
    "    \"\"\"\n",
    "    # Load data from zarr\n",
    "    z = zarr.open(zarr_path, mode='r')\n",
    "    mask_data = z['masks'][:]\n",
    "    \n",
    "    # Save as TIFF\n",
    "    imwrite(output_tiff_path, mask_data)\n",
    "    \n",
    "    return output_tiff_path\n",
    "\n",
    "def cleanup_local_embeddings(output_folder):\n",
    "    \"\"\"\n",
    "    Check for and clean up any existing embeddings from previous interrupted runs\n",
    "    \n",
    "    Args:\n",
    "        output_folder: Path to the output folder containing embeddings\n",
    "    \"\"\"\n",
    "    embed_path = os.path.join(output_folder, \"embed\")\n",
    "    \n",
    "    if os.path.exists(embed_path):\n",
    "        # Look for embedding zarr directories and zip files\n",
    "        for item in os.listdir(embed_path):\n",
    "            item_path = os.path.join(embed_path, item)\n",
    "            if os.path.isdir(item_path) and \"embedding_\" in item and item.endswith(\".zarr\"):\n",
    "                print(f\"Cleaning up leftover embedding directory: {item}\")\n",
    "                shutil.rmtree(item_path)\n",
    "            elif os.path.isfile(item_path) and \"embedding_\" in item and item.endswith(\".zip\"):\n",
    "                print(f\"Cleaning up leftover embedding zip: {item}\")\n",
    "                os.remove(item_path)\n",
    "    \n",
    "    # Check output directory for segmentation files\n",
    "    output_path = os.path.join(output_folder, \"output\")\n",
    "    if os.path.exists(output_path):\n",
    "        for item in os.listdir(output_path):\n",
    "            item_path = os.path.join(output_path, item)\n",
    "            if os.path.isfile(item_path) and \"seg_\" in item and (item.endswith(\".tif\") or item.endswith(\".tiff\")):\n",
    "                print(f\"Cleaning up leftover segmentation file: {item}\")\n",
    "                os.remove(item_path)\n",
    "\n",
    "def process_omero_batch_with_dask(\n",
    "    images_list,\n",
    "    output_folder: str,\n",
    "    container_type: str,\n",
    "    container_id: int,\n",
    "    source_desc: str,\n",
    "    model_type: str = 'vit_l',\n",
    "    batch_size: int = 3,\n",
    "    channel: int = 0,\n",
    "    timepoint: int = 0,\n",
    "    z_slice: int = 0,\n",
    "    z_range: list = None,\n",
    "    segment_all: bool = True,\n",
    "    train_n: int = 3,\n",
    "    validate_n: int = 3,\n",
    "    three_d: bool = False,\n",
    "    resume_from_table: bool = False\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    Process OMERO images in batches for SAM segmentation using dask for lazy loading\n",
    "    and zarr for temporary annotation storage\n",
    "    \n",
    "    Args:\n",
    "        images_list: List of OMERO image objects\n",
    "        output_folder: Path to store temporary files\n",
    "        container_type: Type of OMERO container ('dataset', 'plate', 'project', 'screen', 'image')\n",
    "        container_id: ID of the container\n",
    "        source_desc: Description of the container (for display and tracking)\n",
    "        model_type: SAM model type\n",
    "        batch_size: Number of images to process at once\n",
    "        channel: Channel to segment\n",
    "        timepoint: Timepoint to process\n",
    "        z_slice: Z-slice to process (used only when three_d=False)\n",
    "        z_range: Range of Z-slices to process (optional, for fine control in 3D mode)\n",
    "        segment_all: segment all images in the dataset or only train/validate subset\n",
    "        train_n: Number of training images if not segment_all\n",
    "        validate_n: Number of validation images if not segment_all\n",
    "        three_d: Whether to use 3D volumetric mode\n",
    "        resume_from_table: Whether to resume annotation from an existing tracking table\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (table_id, combined_images)\n",
    "    \"\"\"\n",
    "    # Setup output directories\n",
    "    output_path = os.path.join(output_folder, \"output\")\n",
    "    embed_path = os.path.join(output_folder, \"embed\")\n",
    "    zarr_path = os.path.join(output_folder, \"zarr\")\n",
    "    \n",
    "    # Check for and clean up any existing embeddings from interrupted runs\n",
    "    cleanup_local_embeddings(output_folder)\n",
    "    \n",
    "    # Remove directories if they exist\n",
    "    for path in [output_path, embed_path, zarr_path]:\n",
    "        if os.path.exists(path):\n",
    "            shutil.rmtree(path)\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    # Create or retrieve tracking DataFrame\n",
    "    df = pd.DataFrame(columns=[\n",
    "        \"image_id\", \"image_name\", \"train\", \"validate\", \n",
    "        \"channel\", \"z_slice\", \"timepoint\", \"sam_model\", \"embed_id\", \"label_id\", \"roi_id\", \"is_volumetric\", \"processed\"\n",
    "    ])\n",
    "    \n",
    "    table_id = None\n",
    "    \n",
    "    # Check if we should resume from an existing table\n",
    "    if resume_from_table:\n",
    "        try:\n",
    "            # Get existing tracking table\n",
    "            existing_tables = ezomero.get_table_names(conn, container_type.capitalize(), container_id)\n",
    "            if \"micro_sam_training_data\" in existing_tables:\n",
    "                # Get the table ID and data\n",
    "                table_ids = ezomero.get_table_ids(conn, container_type.capitalize(), container_id)\n",
    "                for tid in table_ids:\n",
    "                    table_name = ezomero.get_table_names(conn, container_type.capitalize(), container_id, tid)\n",
    "                    if table_name == \"micro_sam_training_data\":\n",
    "                        table_id = tid\n",
    "                        existing_df = ezomero.get_table(conn, table_id)\n",
    "                        df = existing_df\n",
    "                        \n",
    "                        print(f\"Resuming from existing table ID: {table_id}\")\n",
    "                        print(f\"Found {len(df)} previously processed images\")\n",
    "                        break\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving existing table: {e}. Starting fresh.\")\n",
    "            resume_from_table = False\n",
    "    \n",
    "    # Get images list (already provided as argument)\n",
    "    combined_images_sequence = np.zeros(len(images_list))  # Initialize sequence array\n",
    "    \n",
    "    # Select images based on segment_all flag\n",
    "    if segment_all:\n",
    "        combined_images = images_list\n",
    "        combined_images_sequence = np.zeros(len(combined_images))  # All treated as training\n",
    "    else:\n",
    "        # Check if we have enough images\n",
    "        if len(images_list) < train_n + validate_n:\n",
    "            print(\"Not enough images in container for training and validation\")\n",
    "            raise ValueError(f\"Need at least {train_n + validate_n} images but found {len(images_list)}\")\n",
    "            \n",
    "        # Select random images for training and validation\n",
    "        train_indices = np.random.choice(len(images_list), train_n, replace=False)\n",
    "        train_images = [images_list[i] for i in train_indices]\n",
    "        \n",
    "        # Get validation images from the remaining ones\n",
    "        validate_candidates = [img for i, img in enumerate(images_list) if i not in train_indices]\n",
    "        validate_images = np.random.choice(validate_candidates, validate_n, replace=False)\n",
    "        \n",
    "        # Interleave the arrays and create sequence markers\n",
    "        combined_images, combined_images_sequence = interleave_arrays(train_images, validate_images)\n",
    "    \n",
    "    # If resuming, filter out already processed images\n",
    "    if resume_from_table:\n",
    "        # Get list of already processed image IDs\n",
    "        processed_ids = set(df[df['processed'] == True]['image_id'].values)\n",
    "        \n",
    "        # Filter combined_images\n",
    "        filtered_images = []\n",
    "        filtered_sequence = []\n",
    "        for i, img in enumerate(combined_images):\n",
    "            if img.getId() not in processed_ids:\n",
    "                filtered_images.append(img)\n",
    "                filtered_sequence.append(combined_images_sequence[i])\n",
    "        \n",
    "        combined_images = filtered_images\n",
    "        combined_images_sequence = np.array(filtered_sequence)\n",
    "        \n",
    "        print(f\"Found {len(combined_images)} remaining images to process\")\n",
    "    \n",
    "    # Calculate total number of batches\n",
    "    total_batches = (len(combined_images) + batch_size - 1) // batch_size\n",
    "    \n",
    "    print(f\"Processing {len(combined_images)} images in {total_batches} batches\")\n",
    "    print(f\"3D mode: {three_d}\")\n",
    "    \n",
    "    # Process images in batches\n",
    "    for batch_idx in range(total_batches):\n",
    "        print(f\"\\nProcessing batch {batch_idx+1}/{total_batches}\")\n",
    "        \n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, len(combined_images))\n",
    "        batch_images = combined_images[start_idx:end_idx]\n",
    "        \n",
    "        # Load batch images as dask arrays for lazy loading\n",
    "        # Use the global conn variable that was already connected instead of trying to get it from dataset\n",
    "        images = []\n",
    "        dask_images = []\n",
    "        image_ids = []\n",
    "        \n",
    "        for image in batch_images:\n",
    "            image_ids.append(image.getId())\n",
    "            \n",
    "            if three_d:\n",
    "                # For 3D mode, we need to get all z-slices\n",
    "                pixels = image.getPrimaryPixels()\n",
    "                # Get the 3D stack directly instead of just one plane\n",
    "                if z_range is not None:\n",
    "                    # Get specific z-range if provided\n",
    "                    img_3d = np.stack([pixels.getPlane(z, channel, timepoint) for z in z_range])\n",
    "                else:\n",
    "                    # Get all z-slices\n",
    "                    img_3d = np.stack([pixels.getPlane(z, channel, timepoint) for z in range(image.getSizeZ())])\n",
    "                images.append(img_3d)\n",
    "                \n",
    "                print(f\"Creating 3D dask array for image {image.getId()} with shape {img_3d.shape}\")\n",
    "                dask_img = get_dask_image(conn, image.getId(), timepoint=timepoint, channel=channel, three_d=True)\n",
    "                dask_images.append(dask_img)\n",
    "            else:\n",
    "                # For 2D mode, get a single plane\n",
    "                pixels = image.getPrimaryPixels()\n",
    "                img = pixels.getPlane(z_slice, channel, timepoint)\n",
    "                images.append(img)\n",
    "                \n",
    "                print(f\"Creating 2D dask array for image {image.getId()}\")\n",
    "                dask_img = get_dask_image(conn, image.getId(), z_slice=z_slice, \n",
    "                                       timepoint=timepoint, channel=channel)\n",
    "                dask_images.append(dask_img)\n",
    "        \n",
    "        # Process batch with SAM using standard numpy arrays for now\n",
    "        # Note: In the future, micro-sam could be updated to work directly with dask\n",
    "        print(\"Starting napari viewer with SAM annotator. Close the viewer window when done.\")\n",
    "        \n",
    "        # Create viewer without context management - following recommended approach\n",
    "        # See error trace for the warnings about gui_qt() being deprecated\n",
    "        viewer = napari.Viewer()\n",
    "        \n",
    "        # Add image series annotator\n",
    "        image_series_annotator(\n",
    "            images, \n",
    "            model_type=model_type,\n",
    "            viewer=viewer,\n",
    "            embedding_path=os.path.join(output_folder, \"embed\"),\n",
    "            output_folder=os.path.join(output_folder, \"output\"),\n",
    "            is_volumetric=three_d  # Pass the three_d flag to use 3D mode\n",
    "        )\n",
    "        \n",
    "        # Start the napari application - this blocks until the viewer is closed\n",
    "        try:\n",
    "            napari.run()\n",
    "            print(\"Napari viewer closed.\")\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Napari viewer was interrupted. Processing results anyway...\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error in napari: {e}\")\n",
    "            \n",
    "        print(\"Processing results from batch...\")\n",
    "        print(\"Done annotating batch, storing results in zarr and uploading to OMERO\")\n",
    "        \n",
    "        # Initialize batch progress tracking\n",
    "        batch_completed = 0\n",
    "        batch_skipped = 0\n",
    "        \n",
    "        # Process results for batch\n",
    "        batch_df = pd.DataFrame(columns=df.columns)\n",
    "        \n",
    "        for n, image in enumerate(batch_images):\n",
    "            local_n = n  # Index within current batch\n",
    "            global_n = start_idx + n  # Global index across all batches\n",
    "            \n",
    "            # Store segmentation mask in zarr before uploading to OMERO\n",
    "            seg_file_path = os.path.join(output_folder, \"output\", f\"seg_{local_n:05d}.tif\")\n",
    "            if not os.path.exists(seg_file_path):\n",
    "                print(f\"Warning: Segmentation file not found for image {image.getId()}, skipping\")\n",
    "                batch_skipped += 1\n",
    "                \n",
    "                # Add a row for skipped image but mark as not processed\n",
    "                is_train = combined_images_sequence[global_n] == 0 if not segment_all else True\n",
    "                is_validate = combined_images_sequence[global_n] == 1 if not segment_all else False\n",
    "                \n",
    "                # Record z-slice information - for 3D we store the range\n",
    "                z_info = z_range if three_d and z_range is not None else \\\n",
    "                       (f\"0-{image.getSizeZ()-1}\" if three_d else z_slice)\n",
    "                \n",
    "                new_row = pd.DataFrame([{\n",
    "                    \"image_id\": image.getId(),\n",
    "                    \"image_name\": image.getName(),\n",
    "                    \"train\": is_train,\n",
    "                    \"validate\": is_validate,\n",
    "                    \"channel\": channel,\n",
    "                    \"z_slice\": z_info,\n",
    "                    \"timepoint\": timepoint,\n",
    "                    \"sam_model\": model_type,\n",
    "                    \"embed_id\": None,\n",
    "                    \"label_id\": None,\n",
    "                    \"roi_id\": None,\n",
    "                    \"is_volumetric\": three_d,\n",
    "                    \"processed\": False\n",
    "                }])\n",
    "                batch_df = pd.concat([batch_df, new_row], ignore_index=True)\n",
    "                continue\n",
    "                \n",
    "            batch_completed += 1\n",
    "            \n",
    "            # Read the segmentation mask\n",
    "            mask_data = imageio.imread(seg_file_path)\n",
    "            \n",
    "            # Store in zarr format for efficient processing\n",
    "            zarr_file_path = store_annotations_in_zarr(mask_data, zarr_path, global_n)\n",
    "            \n",
    "            # Store embedding in zarr format and zip for OMERO upload\n",
    "            embed_zarr = f\"embedding_{local_n:05d}.zarr\"\n",
    "            embed_dir = os.path.join(output_folder, \"embed\")\n",
    "            zip_path = os.path.join(embed_dir, f\"embedding_{global_n:05d}.zip\")\n",
    "            \n",
    "            # Check if the embedding directory exists before trying to zip it\n",
    "            embed_zarr_path = os.path.join(embed_dir, embed_zarr)\n",
    "            if not os.path.exists(embed_zarr_path):\n",
    "                print(f\"Warning: Embedding directory {embed_zarr} not found, skipping embedding upload\")\n",
    "                embed_id = None\n",
    "            else:\n",
    "                with zipfile.ZipFile(zip_path, 'w') as zip_file:\n",
    "                    zip_directory(embed_dir, embed_zarr, zip_file)\n",
    "                \n",
    "                # Upload embedding to OMERO\n",
    "                embed_id = ezomero.post_file_annotation(\n",
    "                    conn,\n",
    "                    str(zip_path),\n",
    "                    ns='microsam.embeddings',\n",
    "                    object_type=\"Image\",\n",
    "                    object_id=image.getId(),\n",
    "                    description=f'SAM embedding ({model_type}), 3D={three_d}'\n",
    "                )\n",
    "            \n",
    "            # Convert zarr annotation to TIFF for OMERO compatibility\n",
    "            tiff_path = os.path.join(output_folder, \"output\", f\"seg_{global_n:05d}.tiff\")\n",
    "            zarr_to_tiff(zarr_file_path, tiff_path)\n",
    "            \n",
    "            # Upload labels and create ROIs\n",
    "            # For 3D data, we need to handle the z-dimension correctly when uploading ROIs\n",
    "            if three_d:\n",
    "                # For 3D data, z_slice is actually all z-slices\n",
    "                z_for_roi = z_range if z_range is not None else range(image.getSizeZ())\n",
    "                # Pass the appropriate parameters for 3D processing\n",
    "                label_id, roi_id = upload_rois_and_labels(\n",
    "                    conn, \n",
    "                    image, \n",
    "                    tiff_path, \n",
    "                    z_for_roi,  # Pass the full range of z-slices\n",
    "                    channel, \n",
    "                    timepoint, \n",
    "                    model_type,\n",
    "                    is_volumetric=True\n",
    "                )\n",
    "            else:\n",
    "                # For 2D data, just pass the z_slice as before\n",
    "                label_id, roi_id = upload_rois_and_labels(\n",
    "                    conn, \n",
    "                    image, \n",
    "                    tiff_path, \n",
    "                    z_slice, \n",
    "                    channel, \n",
    "                    timepoint, \n",
    "                    model_type,\n",
    "                    is_volumetric=False\n",
    "                )\n",
    "            \n",
    "            # Update tracking dataframe\n",
    "            is_train = combined_images_sequence[global_n] == 0 if not segment_all else True\n",
    "            is_validate = combined_images_sequence[global_n] == 1 if not segment_all else False\n",
    "            \n",
    "            # Record z-slice information - for 3D we store the range\n",
    "            z_info = z_range if three_d and z_range is not None else \\\n",
    "                   (f\"0-{image.getSizeZ()-1}\" if three_d else z_slice)\n",
    "            \n",
    "            new_row = pd.DataFrame([{\n",
    "                \"image_id\": image.getId(),\n",
    "                \"image_name\": image.getName(),\n",
    "                \"train\": is_train,\n",
    "                \"validate\": is_validate,\n",
    "                \"channel\": channel,\n",
    "                \"z_slice\": z_info,\n",
    "                \"timepoint\": timepoint,\n",
    "                \"sam_model\": model_type,\n",
    "                \"embed_id\": embed_id,\n",
    "                \"label_id\": label_id,\n",
    "                \"roi_id\": roi_id,\n",
    "                \"is_volumetric\": three_d,\n",
    "                \"processed\": True\n",
    "            }])\n",
    "            batch_df = pd.concat([batch_df, new_row], ignore_index=True)\n",
    "        \n",
    "        # Update the main DataFrame with the batch results\n",
    "        df = pd.concat([df, batch_df], ignore_index=True)\n",
    "        \n",
    "        # Upload batch tracking table to OMERO\n",
    "        if table_id is not None:\n",
    "            # Delete the existing table before creating a new one\n",
    "            try:\n",
    "                print(f\"Deleting existing table with ID: {table_id}\")\n",
    "                # Get the file annotation object for the table\n",
    "                ann = conn.getObject(\"FileAnnotation\", table_id)\n",
    "                if ann:\n",
    "                    # Delete the file annotation (which contains the table)\n",
    "                    conn.deleteObjects(\"FileAnnotation\", [table_id], wait=True)\n",
    "                    print(f\"Existing table deleted successfully\")\n",
    "                else:\n",
    "                    print(f\"Warning: Could not find table with ID: {table_id}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not delete existing table: {e}\")\n",
    "                # Continue anyway, as we'll create a new table\n",
    "        \n",
    "        # Create a new table with the updated data\n",
    "        table_id = ezomero.post_table(\n",
    "            conn, \n",
    "            object_type=container_type.capitalize(), \n",
    "            object_id=container_id, \n",
    "            table=df,\n",
    "            title=\"micro_sam_training_data\"\n",
    "        )\n",
    "        if table_id is None:\n",
    "            print(\"Warning: Failed to create tracking table\")\n",
    "        else:\n",
    "            print(f\"Created new tracking table with ID: {table_id}\")\n",
    "        \n",
    "        print(f\"Batch {batch_idx+1}/{total_batches} results:\")\n",
    "        print(f\"  - Completed: {batch_completed}/{len(batch_images)} images\")\n",
    "        print(f\"  - Skipped: {batch_skipped}/{len(batch_images)} images\")\n",
    "        \n",
    "        if batch_skipped > 0 and batch_idx < total_batches - 1:\n",
    "            # Ask user if they want to continue with next batch or stop here\n",
    "            try:\n",
    "                response = input(\"Some images were skipped. Continue with next batch? (y/n): \")\n",
    "                if response.lower() not in ['y', 'yes']:\n",
    "                    print(\"Stopping processing at user request.\")\n",
    "                    break\n",
    "            except:\n",
    "                # In case of non-interactive environment, continue by default\n",
    "                print(\"Non-interactive environment detected. Continuing with next batch.\")\n",
    "        \n",
    "        # Clean up temporary files for this batch\n",
    "        for n in range(batch_size):  # Use local indexing for cleanup\n",
    "            if start_idx + n >= len(combined_images):  # Skip if we've processed all images\n",
    "                continue\n",
    "                \n",
    "            embed_zip = os.path.join(output_folder, \"embed\", f\"embedding_{n:05d}.zip\")\n",
    "            embed_zarr = os.path.join(output_folder, \"embed\", f\"embedding_{n:05d}.zarr\")\n",
    "            seg_file = os.path.join(output_folder, \"output\", f\"seg_{n:05d}.tif\")\n",
    "            \n",
    "            for path in [embed_zip, seg_file]:\n",
    "                if os.path.exists(path):\n",
    "                    os.remove(path)\n",
    "                    \n",
    "            if os.path.exists(embed_zarr) and os.path.isdir(embed_zarr):\n",
    "                shutil.rmtree(embed_zarr)\n",
    "    \n",
    "    # Final statistics\n",
    "    total_processed = df[df['processed'] == True].shape[0]\n",
    "    total_skipped = df[df['processed'] == False].shape[0]\n",
    "    \n",
    "    print(f\"\\nAll batches completed.\")\n",
    "    print(f\"Total processed: {total_processed} images\")\n",
    "    print(f\"Total skipped: {total_skipped} images\")\n",
    "    print(f\"Final tracking table ID: {table_id} in {source_desc}\")\n",
    "    \n",
    "    return table_id, combined_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images from OMERO and open in napari with micro-sam annotator\n",
    "\n",
    "When using 3D mode (`three_d=True`), the notebook will process entire Z-stacks instead of single slices. This allows for volumetric annotation using micro-SAM's 3D capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running segmentation in batch\n",
    "\n",
    "Note: some warnings from napari are expected in the output here, generally not a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##imput parameters\n",
    "model_type = 'vit_b'\n",
    "segment_all = False\n",
    "train_n = 2   \n",
    "validate_n = 2\n",
    "channel = 3 #which channel to segment starting from 0\n",
    "timepoint = 0\n",
    "z_slice = 4 #TODO for now pick one slice but add option to pick multiple slices by giving a list of z slices, or random slices\n",
    "batch_size = 2 # the number of images to process at once in napari\n",
    "three_d = False\n",
    "resume_from_table = False  # Set to True to continue from a previous run\n",
    "\n",
    "# Configure napari settings\n",
    "settings = get_settings()\n",
    "settings.application.ipy_interactive = False\n",
    "\n",
    "# Run batch processing with dask lazy loading\n",
    "# Get all images from the specified container\n",
    "images_list, source_desc = get_images_from_container(conn, datatype, data_id)\n",
    "\n",
    "if len(images_list) > 0:\n",
    "    table_id, processed_images = process_omero_batch_with_dask(\n",
    "        images_list=images_list,\n",
    "        output_folder=output_directory,\n",
    "        container_type=datatype,\n",
    "        container_id=data_id,\n",
    "        source_desc=source_desc,\n",
    "        model_type=model_type,\n",
    "        batch_size=batch_size,\n",
    "        channel=channel,\n",
    "        timepoint=timepoint,\n",
    "        z_slice=z_slice,\n",
    "        segment_all=segment_all,\n",
    "        train_n=train_n,\n",
    "        validate_n=validate_n,\n",
    "        resume_from_table=resume_from_table\n",
    "    )\n",
    "    print(f\"Finished processing with dask lazy loading. Table ID: {table_id}\")\n",
    "    print(f\"To resume this session later, set resume_from_table=True\")\n",
    "else:\n",
    "    print(f\"No images found in the {datatype} with ID {data_id}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resuming Annotation Sessions\n",
    "\n",
    "This notebook now supports resuming annotation sessions. If you need to stop annotating and continue later:\n",
    "\n",
    "1. Set `resume_from_table = True` in the parameters section\n",
    "2. Run the notebook as usual\n",
    "3. The system will automatically detect previously annotated images and continue with the remaining ones\n",
    "\n",
    "This is useful for:\n",
    "- Long annotation sessions that need to be split over multiple days\n",
    "- Cases where napari was closed accidentally\n",
    "- Continuing after computer restarts or crashes\n",
    "\n",
    "The tracking table in OMERO keeps track of which images have been successfully processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples for processing different container types\n",
    "\n",
    "Here are examples showing how to set up the notebook for different OMERO container types:\n",
    "\n",
    "### Processing a plate\n",
    "```python\n",
    "datatype = \"plate\"\n",
    "data_id = 101  # Your plate ID\n",
    "model_type = 'vit_b'\n",
    "batch_size = 10\n",
    "channel = 0\n",
    "z_slice = 0  # Only used when three_d=False\n",
    "z_range = None  # Optional: specify a range of z-slices (e.g., range(3, 8))\n",
    "timepoint = 0\n",
    "segment_all = False\n",
    "train_n = 20\n",
    "validate_n = 10\n",
    "three_d = False  # Set to True for 3D volumetric processing\n",
    "```\n",
    "\n",
    "### Processing a screen\n",
    "```python\n",
    "datatype = \"screen\"\n",
    "data_id = 5  # Your screen ID\n",
    "model_type = 'vit_b'\n",
    "batch_size = 10\n",
    "channel = 0\n",
    "z_slice = 0\n",
    "z_range = None\n",
    "timepoint = 0\n",
    "segment_all = False\n",
    "train_n = 20\n",
    "validate_n = 10\n",
    "three_d = False\n",
    "```\n",
    "\n",
    "### Processing a project\n",
    "```python\n",
    "datatype = \"project\"\n",
    "data_id = 201  # Your project ID\n",
    "model_type = 'vit_b'\n",
    "batch_size = 10\n",
    "channel = 0\n",
    "z_slice = 0\n",
    "z_range = None\n",
    "timepoint = 0\n",
    "segment_all = False\n",
    "train_n = 20\n",
    "validate_n = 10\n",
    "three_d = False\n",
    "```\n",
    "\n",
    "### Processing in 3D mode\n",
    "```python\n",
    "datatype = \"dataset\"\n",
    "data_id = 201  # Your dataset ID\n",
    "model_type = 'vit_b'\n",
    "batch_size = 5  # Smaller batch size for 3D as it requires more memory\n",
    "channel = 0\n",
    "z_range = range(5, 15)  # Optional: process only a subset of z-slices\n",
    "timepoint = 0\n",
    "segment_all = False\n",
    "train_n = 5\n",
    "validate_n = 5\n",
    "three_d = True  # Enable 3D volumetric processing\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micro-sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
