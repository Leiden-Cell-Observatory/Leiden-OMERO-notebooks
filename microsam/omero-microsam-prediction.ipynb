{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction with finetuned model of micro-sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OMERO Python BlitzGateway\n",
    "import omero\n",
    "from omero.gateway import BlitzGateway\n",
    "import ezomero\n",
    "# Import Numpy\n",
    "import numpy as np\n",
    "import datetime\n",
    "# Import Python System Packages\n",
    "import os\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tifffile import imwrite\n",
    "from dotenv import load_dotenv\n",
    "import imageio\n",
    "import shutil\n",
    "import cv2\n",
    "#micro-sam related imports\n",
    "from micro_sam.automatic_segmentation import get_predictor_and_segmenter, automatic_instance_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup connection with OMERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "conn = BlitzGateway(host=os.environ.get(\"HOST\"), username=os.environ.get(\"USER_NAME\"), passwd=os.environ.get(\"PASSWORD\"), secure=True)\n",
    "connection_status = conn.connect()\n",
    "if connection_status:\n",
    "    print(\"Connected to OMERO Server\")\n",
    "else:\n",
    "    print(\"Connection to OMERO Server Failed\")\n",
    "conn.c.enableKeepAlive(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "home_dir = os.path.expanduser(\"~\")\n",
    "models_dir = os.path.join(home_dir, \"micro-sam_models\")\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "folder_name = f\"micro-sam-{timestamp}\"\n",
    "output_directory = os.path.join(models_dir, folder_name)\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "print(f\"Output directory: {output_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get info from the dataset\n",
    "datatype = \"dataset\" # \"plate\", \"dataset\", \"image\"\n",
    "data_id =  \t502 \n",
    "nucl_channel = 0\n",
    "\n",
    "#validate that data_id matches datatype\n",
    "if datatype == \"plate\":\n",
    "    plate = conn.getObject(\"Plate\", data_id)\n",
    "    print('Plate Name: ', plate.getName())\n",
    "elif datatype == \"dataset\":\n",
    "    dataset = conn.getObject(\"Dataset\", data_id)\n",
    "    print('Dataset Name: ', dataset.getName())\n",
    "elif datatype == \"image\":\n",
    "    image = conn.getObject(\"Image\", data_id)\n",
    "    print('Image Name: ', image.getName())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_automatic_instance_segmentation(image, checkpoint_path, model_type=\"vit_b_lm\", device=None):\n",
    "    \"\"\"Automatic Instance Segmentation (AIS) by training an additional instance decoder in SAM.\n",
    "\n",
    "    NOTE: AIS is supported only for `µsam` models.\n",
    "\n",
    "    Args:\n",
    "        image: The input image.\n",
    "        checkpoint_path: The path to stored checkpoints.\n",
    "        model_type: The choice of the `µsam` model.\n",
    "        device: The device to run the model inference.\n",
    "\n",
    "    Returns:\n",
    "        The instance segmentation.\n",
    "    \"\"\"\n",
    "    # Step 1: Get the 'predictor' and 'segmenter' to perform automatic instance segmentation.\n",
    "    predictor, segmenter = get_predictor_and_segmenter(\n",
    "        model_type=model_type, # choice of the Segment Anything model\n",
    "        checkpoint=checkpoint_path,  # overwrite to pass your own finetuned model.\n",
    "        device=device,  # the device to run the model inference.\n",
    "    )\n",
    "\n",
    "    # Step 2: Get the instance segmentation for the given image.\n",
    "    prediction = automatic_instance_segmentation(\n",
    "        predictor=predictor,  # the predictor for the Segment Anything model.\n",
    "        segmenter=segmenter,  # the segmenter class responsible for generating predictions.\n",
    "        input_path=image,\n",
    "        ndim=2,\n",
    "    )\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_omero_prediction_batch(\n",
    "    dataset,\n",
    "    output_folder: str,\n",
    "    model_path: str,\n",
    "    model_type: str = 'vit_l',\n",
    "    batch_size: int = 3,\n",
    "    channel: int = 0,\n",
    "    timepoint: int = 0,\n",
    "    z_slice: int = 0,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Process OMERO dataset in batches for automatic instance segmentation using fine-tuned SAM model\n",
    "    \n",
    "    Args:\n",
    "        dataset: OMERO dataset object\n",
    "        output_folder: Path to store temporary files\n",
    "        model_path: Path to fine-tuned model checkpoint\n",
    "        model_type: SAM model type\n",
    "        batch_size: Number of images to process at once\n",
    "        channel: Channel to segment\n",
    "        timepoint: Timepoint to process\n",
    "        z_slice: Z-slice to process\n",
    "    \"\"\"\n",
    "    # Setup output directory\n",
    "    output_path = os.path.join(output_folder, \"predictions\")\n",
    "    \n",
    "    # Remove directory if exists and create fresh\n",
    "    if os.path.exists(output_path):\n",
    "        shutil.rmtree(output_path)\n",
    "    os.makedirs(output_path)\n",
    "    \n",
    "    # Get all images from dataset\n",
    "    images_dataset = list(dataset.listChildren())\n",
    "    total_batches = (len(images_dataset) + batch_size - 1) // batch_size\n",
    "\n",
    "    # Create tracking dataframe\n",
    "    df = pd.DataFrame(columns=[\n",
    "        \"image_id\", \"image_name\", \"channel\", \"timepoint\", \n",
    "        \"sam_model\", \"label_id\", \"roi_id\"\n",
    "    ])\n",
    "    \n",
    "    # Process images in batches\n",
    "    for batch_idx in range(total_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, len(images_dataset))\n",
    "        batch_images = images_dataset[start_idx:end_idx]\n",
    "        \n",
    "        # Process each image in batch\n",
    "        for n, image in enumerate(batch_images):\n",
    "            local_n = n\n",
    "            \n",
    "            # Get image plane\n",
    "            pixels = image.getPrimaryPixels()\n",
    "            img = pixels.getPlane(z_slice, channel, timepoint)\n",
    "            \n",
    "            # Run automatic instance segmentation\n",
    "            prediction = run_automatic_instance_segmentation(\n",
    "                image=img, \n",
    "                checkpoint_path=model_path,\n",
    "                model_type=model_type,\n",
    "                device='cuda'\n",
    "            )\n",
    "            \n",
    "            # Save prediction\n",
    "            pred_file = os.path.join(output_path, f\"pred_{local_n:05d}.tif\")\n",
    "            imageio.imwrite(pred_file, prediction)\n",
    "            \n",
    "            # Upload prediction and ROIs\n",
    "            label_id, roi_id = upload_prediction_and_rois(\n",
    "                conn, \n",
    "                image, \n",
    "                pred_file, \n",
    "                z_slice, \n",
    "                channel, \n",
    "                timepoint, \n",
    "                model_type\n",
    "            )\n",
    "            \n",
    "            # Update tracking dataframe\n",
    "            new_row = pd.DataFrame([{\n",
    "                \"image_id\": image.getId(),\n",
    "                \"image_name\": image.getName(),\n",
    "                \"channel\": channel,\n",
    "                \"z_slice\": z_slice,\n",
    "                \"timepoint\": timepoint,\n",
    "                \"sam_model\": model_type,\n",
    "                \"label_id\": label_id,\n",
    "                \"roi_id\": roi_id\n",
    "            }])\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "            \n",
    "            # Clean up prediction file\n",
    "            if os.path.exists(pred_file):\n",
    "                os.remove(pred_file)\n",
    "    \n",
    "    # Upload tracking table\n",
    "    table_id = ezomero.post_table(\n",
    "        conn, \n",
    "        object_type=\"Dataset\", \n",
    "        object_id=dataset.getId(), \n",
    "        table=df,\n",
    "        title=\"micro_sam_prediction_data\"\n",
    "    )\n",
    "    \n",
    "    return table_id\n",
    "\n",
    "\n",
    "def mask_to_contour(mask):\n",
    "    \"\"\"Converts a binary mask to a list of ROI coordinates.\n",
    "\n",
    "    Args:\n",
    "        mask (np.ndarray): binary mask\n",
    "\n",
    "    Returns:\n",
    "        list: list of ROI coordinates\n",
    "    \"\"\"\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "def label_to_rois(label_img, z_slice, channel, timepoint):\n",
    "    \"\"\"\n",
    "    Convert a 2D label image to OMERO ROI shapes\n",
    "    \n",
    "    Args:\n",
    "        label_img (np.ndarray): 2D labeled image\n",
    "        z_slice (int): Z-slice index\n",
    "        channel (int): Channel index\n",
    "        timepoint (int): Time point index\n",
    "    \n",
    "    Returns:\n",
    "        list: List of OMERO shape objects\n",
    "    \"\"\"\n",
    "    shapes = []\n",
    "    unique_labels = np.unique(label_img)\n",
    "    \n",
    "    # Skip background (label 0)\n",
    "    for label in unique_labels[1:]:\n",
    "        # Create binary mask for this label\n",
    "        mask = (label_img == label).astype(np.uint8)\n",
    "        \n",
    "        # Get contours\n",
    "        contours = mask_to_contour(mask)\n",
    "        \n",
    "        # Convert each contour to polygon ROI\n",
    "        for contour in contours:\n",
    "            contour = contour[:, 0, :]  # Reshape to (N, 2)\n",
    "            # Create polygon without text parameter\n",
    "            poly = ezomero.rois.Polygon(\n",
    "                points=contour,  # explicitly name the points parameter\n",
    "                z=z_slice,\n",
    "                c=channel,\n",
    "                t=timepoint\n",
    "            )\n",
    "            shapes.append(poly)\n",
    "    \n",
    "    return shapes\n",
    "\n",
    "def upload_prediction_and_rois(conn, image, pred_file, z_slice, channel, timepoint, model_type):\n",
    "    \"\"\"\n",
    "    Upload prediction map and ROIs for automatically segmented image\n",
    "    \"\"\"\n",
    "    # Upload prediction as attachment\n",
    "    label_id = ezomero.post_file_annotation(\n",
    "        conn,\n",
    "        str(pred_file),\n",
    "        ns='microsam.automatic_prediction',\n",
    "        object_type=\"Image\",\n",
    "        object_id=image.getId(),\n",
    "        description=f'SAM automatic instance segmentation ({model_type})'\n",
    "    )\n",
    "    \n",
    "    # Create ROIs from prediction\n",
    "    pred_img = imageio.imread(pred_file)\n",
    "    shapes = label_to_rois(pred_img, z_slice, channel, timepoint)\n",
    "    \n",
    "    if shapes:\n",
    "        roi_id = ezomero.post_roi(\n",
    "            conn,\n",
    "            image.getId(),\n",
    "            shapes,\n",
    "            name=f'SAM_automatic_{model_type}',\n",
    "            description='micro_sam.automatic_instance_segmentation'\n",
    "        )\n",
    "    else:\n",
    "        roi_id = None\n",
    "        \n",
    "    return label_id, roi_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_folder = 'C:\\\\models\\\\checkpoints\\\\sam'\n",
    "best_checkpoint = os.path.join(model_folder, \"best.pt\")\n",
    "model_type = \"vit_b\"\n",
    "channel = 3\n",
    "batch_size = 1\n",
    "timepoint = 0\n",
    "z_slice = 5\n",
    "table_id = process_omero_prediction_batch(\n",
    "    dataset=dataset,\n",
    "    output_folder=output_directory,\n",
    "    model_path=best_checkpoint,\n",
    "    model_type=model_type,\n",
    "    batch_size=batch_size,\n",
    "    channel=channel,\n",
    "    timepoint=timepoint,\n",
    "    z_slice=z_slice\n",
    ")\n",
    "print(\"Prediction Table ID:\", table_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micro-sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
