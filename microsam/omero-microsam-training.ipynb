{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omero.gateway import BlitzGateway\n",
    "import ezomero\n",
    "#load dotenv for OMERO login\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from tifffile import imsave, imwrite, imread\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import datetime\n",
    "import shutil\n",
    "\n",
    "from torch_em.util.debug import check_loader\n",
    "from torch_em.data import MinInstanceSampler\n",
    "from torch_em.util.util import get_random_colors\n",
    "\n",
    "import micro_sam.training as sam_training\n",
    "from micro_sam.sample_data import fetch_tracking_example_data, fetch_tracking_segmentation_data\n",
    "from micro_sam.automatic_segmentation import get_predictor_and_segmenter, automatic_instance_segmentation\n",
    "\n",
    "\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "# Reload all src submodules\n",
    "src_modules = [\n",
    "    \"src.omero_functions\",\n",
    "    \"src.file_io_functions\",\n",
    "    \"src.image_functions\",\n",
    "    \"src.utils\",\n",
    "    \"src.processing_pipeline\",\n",
    "]\n",
    "\n",
    "\n",
    "def reload_module(module_name):\n",
    "    if module_name in sys.modules:\n",
    "        importlib.reload(sys.modules[module_name])\n",
    "    return __import__(module_name)\n",
    "\n",
    "\n",
    "for module in src_modules:\n",
    "    reload_module(module)\n",
    "\n",
    "# Re-import after reloading to ensure we have the latest versions\n",
    "from src.omero_functions import (\n",
    "    print_object_details,\n",
    "    get_images_from_container,\n",
    "    get_dask_image,\n",
    "    upload_rois_and_labels,\n",
    "    initialize_tracking_table,\n",
    "    update_tracking_table_rows,\n",
    "    get_dask_image_multiple,\n",
    "    get_dask_dimensions,\n",
    ")\n",
    "from src.file_io_functions import (\n",
    "    zip_directory,\n",
    "    store_annotations_in_zarr,\n",
    "    zarr_to_tiff,\n",
    "    cleanup_local_embeddings,\n",
    "    organize_local_outputs,\n",
    "    save_annotations_schema,\n",
    ")\n",
    "from src.image_functions import label_to_rois, generate_patch_coordinates, extract_patch\n",
    "from src.utils import NumpyEncoder, interleave_arrays\n",
    "from src.processing_pipeline import process_omero_batch\n",
    "\n",
    "from napari.settings import get_settings\n",
    "\n",
    "get_settings().application.ipy_interactive = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup connection with OMERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:created connection (uuid=3f06f483-a349-4350-9782-d3fcaf74d3c6)\n",
      "INFO:omero.util.Resources:Starting\n",
      "INFO:omero.util.Resources:Starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to OMERO Server\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "# Ask for password if not set\n",
    "if not os.environ.get(\"PASSWORD\"):\n",
    "    from getpass import getpass\n",
    "\n",
    "    os.environ[\"PASSWORD\"] = getpass(\"Enter OMERO server password: \")\n",
    "\n",
    "conn = BlitzGateway(\n",
    "    host=os.environ.get(\"HOST\"),\n",
    "    username=os.environ.get(\"USER_NAME\"),\n",
    "    passwd=os.environ.get(\"PASSWORD\"),\n",
    "    group=os.environ.get(\"GROUP\"),\n",
    "    secure=True,\n",
    ")\n",
    "\n",
    "connection_status = conn.connect()\n",
    "if connection_status:\n",
    "    print(\"Connected to OMERO Server\")\n",
    "else:\n",
    "    print(\"Connection to OMERO Server Failed\")\n",
    "conn.c.enableKeepAlive(60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get info from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Project Details:\n",
      "- Name: Senescence\n",
      "- ID: 101\n",
      "- Owner: root root\n",
      "- Group: system\n",
      "- Number of datasets: 3\n",
      "- Total images: 6\n"
     ]
    }
   ],
   "source": [
    "datatype = \"project\"  # \"screen\", \"plate\", \"project\", \"dataset\", \"image\"\n",
    "data_id = 101\n",
    "trainingset_name = \"micro_sam_training_data_20240602\"\n",
    "\n",
    "\n",
    "# Validate that data_id matches datatype and print details\n",
    "if datatype == \"project\":\n",
    "    project = conn.getObject(\"Project\", data_id)\n",
    "    if project is None:\n",
    "        raise ValueError(f\"Project with ID {data_id} not found\")\n",
    "    print_object_details(conn, project, \"project\")\n",
    "\n",
    "elif datatype == \"plate\":\n",
    "    plate = conn.getObject(\"Plate\", data_id)\n",
    "    if plate is None:\n",
    "        raise ValueError(f\"Plate with ID {data_id} not found\")\n",
    "    print_object_details(conn, plate, \"plate\")\n",
    "\n",
    "elif datatype == \"dataset\":\n",
    "    dataset = conn.getObject(\"Dataset\", data_id)\n",
    "    if dataset is None:\n",
    "        raise ValueError(f\"Dataset with ID {data_id} not found\")\n",
    "    print_object_details(conn, dataset, \"dataset\")\n",
    "\n",
    "elif datatype == \"image\":\n",
    "    image = conn.getObject(\"Image\", data_id)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Image with ID {data_id} not found\")\n",
    "    print_object_details(conn, image, \"image\")\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Invalid datatype specified\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define output folders for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "home_dir = os.path.expanduser(\"~\")\n",
    "models_dir = os.path.join(home_dir, \"micro-sam_models\")\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "folder_name = f\"micro-sam-{timestamp}\"\n",
    "output_directory = os.path.join(models_dir, folder_name)\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "output_directory = os.path.abspath(output_directory)\n",
    "#output_directory = os.path.abspath(\"C:\\\\Users\\\\mwpaul\\\\micro-sam_models\\\\micro-sam-20250207_095503\")\n",
    "print(f\"Output directory: {output_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting data from OMERO using the attached table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_specific_table(conn, datatype, dataset_id, table_name=\"micro_sam_training_data\"):\n",
    "    \"\"\"\n",
    "    Find and return a specific table attached to a dataset by its name.\n",
    "    \n",
    "    Args:\n",
    "        conn: OMERO connection\n",
    "        datatype: Type of the dataset (e.g., \"project\", \"dataset\")\n",
    "        dataset_id: ID of the dataset to search\n",
    "        table_name: Name of the table file to find\n",
    "        \n",
    "    Returns:\n",
    "        table: Table data as pandas DataFrame or list of lists\n",
    "        file_ann_id: ID of the file annotation containing the table\n",
    "    \"\"\"\n",
    "    # Get all file annotations on the dataset\n",
    "    file_ann_ids = ezomero.get_file_annotation_ids(conn, datatype, dataset_id)\n",
    "    \n",
    "    # Get original file details to check names\n",
    "    for ann_id in file_ann_ids:\n",
    "        ann = conn.getObject(\"FileAnnotation\", ann_id)\n",
    "        if ann is None:\n",
    "            continue\n",
    "            \n",
    "        orig_file = ann.getFile()\n",
    "        if orig_file.getName() == table_name:\n",
    "            try:\n",
    "                table = ezomero.get_table(conn, ann_id)\n",
    "                return table, ann_id\n",
    "            except Exception as e:\n",
    "                print(f\"Found file {table_name} but failed to load as table: {e}\")\n",
    "                continue\n",
    "                \n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found table micro_sam_training_data_20240602 in file annotation 344\n",
      "   image_id  channel  z_slice  timepoint  patch_x  patch_y  patch_width  \\\n",
      "0       254        1        0         10      367      364          256   \n",
      "1       254        1        0         10     1324      956          256   \n",
      "2       253        1        0         11     1517      488          256   \n",
      "3       253        1        0         12      432      912          256   \n",
      "4       256        1        0          1     1586     1706          256   \n",
      "\n",
      "   patch_height  image_name sam_model embed_id label_id roi_id  \\\n",
      "0           256  r01c03.tif  vit_b_lm     None      320      1   \n",
      "1           256  r01c03.tif  vit_b_lm      321      322      2   \n",
      "2           256  r01c04.tif  vit_b_lm      323      324      3   \n",
      "3           256  r01c04.tif  vit_b_lm      325      326      4   \n",
      "4           256  r01c01.tif  vit_b_lm      327      328      5   \n",
      "\n",
      "  schema_attachment_id  train  validate  is_volumetric  processed  is_patch  \n",
      "0                 None   True     False          False       True      True  \n",
      "1                 None   True     False          False       True      True  \n",
      "2                 None  False      True          False       True      True  \n",
      "3                 None  False      True          False       True      True  \n",
      "4                 None   True     False          False       True      True  \n"
     ]
    }
   ],
   "source": [
    "table, file_ann_id = get_specific_table(conn, datatype, data_id, trainingset_name)\n",
    "if table is not None:\n",
    "    print(f\"Found table {trainingset_name} in file annotation {file_ann_id}\")\n",
    "    # If pandas DataFrame:\n",
    "    print(table.head())\n",
    "else:\n",
    "    print(f\"No table named {trainingset_name} found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 training images and 6 validation images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing training data:   0%|          | 0/6 [00:00<?, ?it/s]INFO:omero.gateway:Registered 3f06f483-a349-4350-9782-d3fcaf74d3c6/876bd6b7-f39d-44ea-be9a-4a44587c93a8omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "INFO:omero.gateway:Registered 3f06f483-a349-4350-9782-d3fcaf74d3c6/876bd6b7-f39d-44ea-be9a-4a44587c93a8omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 0 - Image ID: 254, Patch: True, Dimensions: 256x256 at (367,364)\n",
      "  2D Patch Request - start_coords: (367, 364, 0, 1, 10), dimensions: 256x256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Unregistered 3f06f483-a349-4350-9782-d3fcaf74d3c6/876bd6b7-f39d-44ea-be9a-4a44587c93a8omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "Preparing training data:  17%|█▋        | 1/6 [00:00<00:03,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Returned array shape: (256, 256, 1, 1, 1)\n",
      "  Extracted 2D shape: (256, 256)\n",
      "  Saved 2D TIFF to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\training_input\\input_00000.tif with shape (256, 256)\n",
      "  Label shape: (256, 256) saved to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\training_label\\label_00000.tif\n",
      "Item 1 - Image ID: 254, Patch: True, Dimensions: 256x256 at (1324,956)\n",
      "  2D Patch Request - start_coords: (1324, 956, 0, 1, 10), dimensions: 256x256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Registered 3f06f483-a349-4350-9782-d3fcaf74d3c6/de8c44b4-678e-4ae7-a57e-12f2f80b9095omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "INFO:omero.gateway:Unregistered 3f06f483-a349-4350-9782-d3fcaf74d3c6/de8c44b4-678e-4ae7-a57e-12f2f80b9095omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "INFO:omero.gateway:Unregistered 3f06f483-a349-4350-9782-d3fcaf74d3c6/de8c44b4-678e-4ae7-a57e-12f2f80b9095omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "Preparing training data:  33%|███▎      | 2/6 [00:01<00:02,  1.70it/s]INFO:omero.gateway:Registered 3f06f483-a349-4350-9782-d3fcaf74d3c6/5ab43ca5-9763-4f1a-adf2-662ab7515e53omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "INFO:omero.gateway:Registered 3f06f483-a349-4350-9782-d3fcaf74d3c6/5ab43ca5-9763-4f1a-adf2-662ab7515e53omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Returned array shape: (256, 256, 1, 1, 1)\n",
      "  Extracted 2D shape: (256, 256)\n",
      "  Saved 2D TIFF to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\training_input\\input_00001.tif with shape (256, 256)\n",
      "  Label shape: (256, 256) saved to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\training_label\\label_00001.tif\n",
      "Item 2 - Image ID: 256, Patch: True, Dimensions: 256x256 at (1586,1706)\n",
      "  2D Patch Request - start_coords: (1586, 1706, 0, 1, 1), dimensions: 256x256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Unregistered 3f06f483-a349-4350-9782-d3fcaf74d3c6/5ab43ca5-9763-4f1a-adf2-662ab7515e53omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "Preparing training data:  50%|█████     | 3/6 [00:01<00:01,  1.70it/s]INFO:omero.gateway:Registered 3f06f483-a349-4350-9782-d3fcaf74d3c6/17734cac-e59c-4a04-81fb-1378d526e99domero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "INFO:omero.gateway:Registered 3f06f483-a349-4350-9782-d3fcaf74d3c6/17734cac-e59c-4a04-81fb-1378d526e99domero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Returned array shape: (256, 256, 1, 1, 1)\n",
      "  Extracted 2D shape: (256, 256)\n",
      "  Saved 2D TIFF to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\training_input\\input_00002.tif with shape (256, 256)\n",
      "  Label shape: (256, 256) saved to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\training_label\\label_00002.tif\n",
      "Item 3 - Image ID: 256, Patch: True, Dimensions: 256x256 at (141,1146)\n",
      "  2D Patch Request - start_coords: (141, 1146, 0, 1, 2), dimensions: 256x256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Unregistered 3f06f483-a349-4350-9782-d3fcaf74d3c6/17734cac-e59c-4a04-81fb-1378d526e99domero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "Preparing training data:  67%|██████▋   | 4/6 [00:02<00:01,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Returned array shape: (256, 256, 1, 1, 1)\n",
      "  Extracted 2D shape: (256, 256)\n",
      "  Saved 2D TIFF to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\training_input\\input_00003.tif with shape (256, 256)\n",
      "  Label shape: (256, 256) saved to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\training_label\\label_00003.tif\n",
      "Item 4 - Image ID: 252, Patch: True, Dimensions: 256x256 at (1637,1510)\n",
      "  2D Patch Request - start_coords: (1637, 1510, 0, 1, 8), dimensions: 256x256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Registered 3f06f483-a349-4350-9782-d3fcaf74d3c6/f2836016-f551-462c-b591-9055c515fb2aomero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "INFO:omero.gateway:Unregistered 3f06f483-a349-4350-9782-d3fcaf74d3c6/f2836016-f551-462c-b591-9055c515fb2aomero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "INFO:omero.gateway:Unregistered 3f06f483-a349-4350-9782-d3fcaf74d3c6/f2836016-f551-462c-b591-9055c515fb2aomero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "Preparing training data:  83%|████████▎ | 5/6 [00:02<00:00,  1.76it/s]INFO:omero.gateway:Registered 3f06f483-a349-4350-9782-d3fcaf74d3c6/be0f5aea-df6b-44b4-a712-77099ca3360comero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "INFO:omero.gateway:Registered 3f06f483-a349-4350-9782-d3fcaf74d3c6/be0f5aea-df6b-44b4-a712-77099ca3360comero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Returned array shape: (256, 256, 1, 1, 1)\n",
      "  Extracted 2D shape: (256, 256)\n",
      "  Saved 2D TIFF to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\training_input\\input_00004.tif with shape (256, 256)\n",
      "  Label shape: (256, 256) saved to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\training_label\\label_00004.tif\n",
      "Item 5 - Image ID: 252, Patch: True, Dimensions: 256x256 at (312,138)\n",
      "  2D Patch Request - start_coords: (312, 138, 0, 1, 3), dimensions: 256x256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Unregistered 3f06f483-a349-4350-9782-d3fcaf74d3c6/be0f5aea-df6b-44b4-a712-77099ca3360comero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "Preparing training data: 100%|██████████| 6/6 [00:03<00:00,  1.75it/s]\n",
      "Preparing training data: 100%|██████████| 6/6 [00:03<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Returned array shape: (256, 256, 1, 1, 1)\n",
      "  Extracted 2D shape: (256, 256)\n",
      "  Saved 2D TIFF to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\training_input\\input_00005.tif with shape (256, 256)\n",
      "  Label shape: (256, 256) saved to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\training_label\\label_00005.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing val data:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 0 - Image ID: 253, Patch: True, Dimensions: 256x256 at (1517,488)\n",
      "  2D Patch Request - start_coords: (1517, 488, 0, 1, 11), dimensions: 256x256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Registered 3f06f483-a349-4350-9782-d3fcaf74d3c6/7b523d1a-22bd-401b-8b27-a3d675d1a1aaomero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "INFO:omero.gateway:Unregistered 3f06f483-a349-4350-9782-d3fcaf74d3c6/7b523d1a-22bd-401b-8b27-a3d675d1a1aaomero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "INFO:omero.gateway:Unregistered 3f06f483-a349-4350-9782-d3fcaf74d3c6/7b523d1a-22bd-401b-8b27-a3d675d1a1aaomero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "Preparing val data:  17%|█▋        | 1/6 [00:00<00:02,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Returned array shape: (256, 256, 1, 1, 1)\n",
      "  Extracted 2D shape: (256, 256)\n",
      "  Saved 2D TIFF to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\val_input\\input_00000.tif with shape (256, 256)\n",
      "  Label shape: (256, 256) saved to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\val_label\\label_00000.tif\n",
      "Item 1 - Image ID: 253, Patch: True, Dimensions: 256x256 at (432,912)\n",
      "  2D Patch Request - start_coords: (432, 912, 0, 1, 12), dimensions: 256x256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Registered 3f06f483-a349-4350-9782-d3fcaf74d3c6/40e3239d-d9eb-41ec-b74b-11435a29a234omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "INFO:omero.gateway:Unregistered 3f06f483-a349-4350-9782-d3fcaf74d3c6/40e3239d-d9eb-41ec-b74b-11435a29a234omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "INFO:omero.gateway:Unregistered 3f06f483-a349-4350-9782-d3fcaf74d3c6/40e3239d-d9eb-41ec-b74b-11435a29a234omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "Preparing val data:  33%|███▎      | 2/6 [00:01<00:02,  1.75it/s]INFO:omero.gateway:Registered 3f06f483-a349-4350-9782-d3fcaf74d3c6/75ddc1ce-e252-4f5d-bfad-8fa30d47ed7eomero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "INFO:omero.gateway:Registered 3f06f483-a349-4350-9782-d3fcaf74d3c6/75ddc1ce-e252-4f5d-bfad-8fa30d47ed7eomero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Returned array shape: (256, 256, 1, 1, 1)\n",
      "  Extracted 2D shape: (256, 256)\n",
      "  Saved 2D TIFF to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\val_input\\input_00001.tif with shape (256, 256)\n",
      "  Label shape: (256, 256) saved to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\val_label\\label_00001.tif\n",
      "Item 2 - Image ID: 251, Patch: True, Dimensions: 256x256 at (1615,1124)\n",
      "  2D Patch Request - start_coords: (1615, 1124, 0, 1, 5), dimensions: 256x256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Unregistered 3f06f483-a349-4350-9782-d3fcaf74d3c6/75ddc1ce-e252-4f5d-bfad-8fa30d47ed7eomero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "Preparing val data:  50%|█████     | 3/6 [00:01<00:01,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Returned array shape: (256, 256, 1, 1, 1)\n",
      "  Extracted 2D shape: (256, 256)\n",
      "  Saved 2D TIFF to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\val_input\\input_00002.tif with shape (256, 256)\n",
      "  Label shape: (256, 256) saved to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\val_label\\label_00002.tif\n",
      "Item 3 - Image ID: 251, Patch: True, Dimensions: 256x256 at (162,627)\n",
      "  2D Patch Request - start_coords: (162, 627, 0, 1, 12), dimensions: 256x256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Registered 3f06f483-a349-4350-9782-d3fcaf74d3c6/93fd1c4c-c444-4cda-9f4a-a586a4e459b8omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "INFO:omero.gateway:Unregistered 3f06f483-a349-4350-9782-d3fcaf74d3c6/93fd1c4c-c444-4cda-9f4a-a586a4e459b8omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "INFO:omero.gateway:Unregistered 3f06f483-a349-4350-9782-d3fcaf74d3c6/93fd1c4c-c444-4cda-9f4a-a586a4e459b8omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "Preparing val data:  67%|██████▋   | 4/6 [00:02<00:01,  1.83it/s]INFO:omero.gateway:Registered 3f06f483-a349-4350-9782-d3fcaf74d3c6/6ff312ee-c38a-47df-8596-21b1e377ff1comero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "INFO:omero.gateway:Registered 3f06f483-a349-4350-9782-d3fcaf74d3c6/6ff312ee-c38a-47df-8596-21b1e377ff1comero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Returned array shape: (256, 256, 1, 1, 1)\n",
      "  Extracted 2D shape: (256, 256)\n",
      "  Saved 2D TIFF to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\val_input\\input_00003.tif with shape (256, 256)\n",
      "  Label shape: (256, 256) saved to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\val_label\\label_00003.tif\n",
      "Item 4 - Image ID: 255, Patch: True, Dimensions: 256x256 at (1158,1150)\n",
      "  2D Patch Request - start_coords: (1158, 1150, 0, 1, 9), dimensions: 256x256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Unregistered 3f06f483-a349-4350-9782-d3fcaf74d3c6/6ff312ee-c38a-47df-8596-21b1e377ff1comero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "Preparing val data:  83%|████████▎ | 5/6 [00:02<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Returned array shape: (256, 256, 1, 1, 1)\n",
      "  Extracted 2D shape: (256, 256)\n",
      "  Saved 2D TIFF to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\val_input\\input_00004.tif with shape (256, 256)\n",
      "  Label shape: (256, 256) saved to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\val_label\\label_00004.tif\n",
      "Item 5 - Image ID: 255, Patch: True, Dimensions: 256x256 at (5,506)\n",
      "  2D Patch Request - start_coords: (5, 506, 0, 1, 8), dimensions: 256x256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:omero.gateway:Registered 3f06f483-a349-4350-9782-d3fcaf74d3c6/c113cf5b-6830-4b7c-9d71-00a1ffacc270omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "INFO:omero.gateway:Unregistered 3f06f483-a349-4350-9782-d3fcaf74d3c6/c113cf5b-6830-4b7c-9d71-00a1ffacc270omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "INFO:omero.gateway:Unregistered 3f06f483-a349-4350-9782-d3fcaf74d3c6/c113cf5b-6830-4b7c-9d71-00a1ffacc270omero.api.RawPixelsStore -t -e 1.1:tcp -h 172.19.0.9 -p 34289 -t 60000\n",
      "Preparing val data: 100%|██████████| 6/6 [00:03<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Returned array shape: (256, 256, 1, 1, 1)\n",
      "  Extracted 2D shape: (256, 256)\n",
      "  Saved 2D TIFF to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\val_input\\input_00005.tif with shape (256, 256)\n",
      "  Label shape: (256, 256) saved to C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\\val_label\\label_00005.tif\n",
      "Training data successfully saved to: C:\\Users\\Maarten\\micro-sam_models\\micro-sam-20250604_112234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a reusable function to prepare training/validation data from OMERO table\n",
    "def prepare_dataset_from_table(conn, df, output_dir, subset_type=\"training\", tmp_dir=None):\n",
    "    \"\"\"\n",
    "    Prepare dataset from tracking table\n",
    "    \n",
    "    Args:\n",
    "        conn: OMERO connection\n",
    "        df: DataFrame with tracking info\n",
    "        output_dir: Base output directory\n",
    "        subset_type: \"training\" or \"val\"\n",
    "        tmp_dir: Temporary directory for downloading annotations\n",
    "        \n",
    "    Returns:\n",
    "        (input_dir, label_dir): Paths to the input and label directories\n",
    "    \"\"\"\n",
    "    if tmp_dir is None:\n",
    "        tmp_dir = os.path.join(output_dir, \"tmp\")\n",
    "        os.makedirs(tmp_dir, exist_ok=True)\n",
    "        \n",
    "    input_dir = os.path.join(output_dir, f\"{subset_type}_input\")\n",
    "    label_dir = os.path.join(output_dir, f\"{subset_type}_label\")\n",
    "    os.makedirs(input_dir, exist_ok=True)\n",
    "    os.makedirs(label_dir, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        from tqdm import tqdm\n",
    "        progress_fn = tqdm\n",
    "    except ImportError:\n",
    "        # Simple progress function if tqdm is not available\n",
    "        def progress_fn(x, **kwargs):\n",
    "            return x\n",
    "    \n",
    "    for n in progress_fn(range(len(df)), desc=f\"Preparing {subset_type} data\"):\n",
    "        try:\n",
    "            # Extract metadata\n",
    "            image_id = int(df.iloc[n]['image_id'])\n",
    "            \n",
    "            # Handle z_slice - could be int, string representation of list, or NaN\n",
    "            z_slice = df.iloc[n]['z_slice']\n",
    "            if pd.isna(z_slice):\n",
    "                z_slice = 0\n",
    "            elif isinstance(z_slice, str) and z_slice.startswith('['):\n",
    "                try:\n",
    "                    z_slice = eval(z_slice)\n",
    "                    if isinstance(z_slice, list) and len(z_slice) > 0:\n",
    "                        z_slice = z_slice[0]  # Use first slice for 2D\n",
    "                except:\n",
    "                    z_slice = 0\n",
    "            \n",
    "            # Handle other metadata columns\n",
    "            channel = int(df.iloc[n]['channel']) if pd.notna(df.iloc[n]['channel']) else 0\n",
    "            timepoint = int(df.iloc[n]['timepoint']) if pd.notna(df.iloc[n]['timepoint']) else 0\n",
    "            is_volumetric = bool(df.iloc[n]['is_volumetric']) if 'is_volumetric' in df.columns and pd.notna(df.iloc[n]['is_volumetric']) else False\n",
    "            \n",
    "            # Get patch information\n",
    "            is_patch = bool(df.iloc[n]['is_patch']) if 'is_patch' in df.columns and pd.notna(df.iloc[n]['is_patch']) else False\n",
    "            patch_x = int(df.iloc[n]['patch_x']) if pd.notna(df.iloc[n]['patch_x']) else 0\n",
    "            patch_y = int(df.iloc[n]['patch_y']) if pd.notna(df.iloc[n]['patch_y']) else 0\n",
    "            patch_width = int(df.iloc[n]['patch_width']) if pd.notna(df.iloc[n]['patch_width']) else 0\n",
    "            patch_height = int(df.iloc[n]['patch_height']) if pd.notna(df.iloc[n]['patch_height']) else 0\n",
    "            \n",
    "            # Debug patch dimensions\n",
    "            print(f\"Item {n} - Image ID: {image_id}, Patch: {is_patch}, Dimensions: {patch_width}x{patch_height} at ({patch_x},{patch_y})\")\n",
    "            \n",
    "            # Process based on whether it's 3D volumetric or 2D\n",
    "            if is_volumetric:\n",
    "                # Handle 3D volumetric data\n",
    "                # Determine which z-slices to load\n",
    "                if isinstance(z_slice, list):\n",
    "                    z_slices = z_slice\n",
    "                elif z_slice == 'all':\n",
    "                    # Get image object to determine size\n",
    "                    omero_image, _ = ezomero.get_image(conn, image_id, no_pixels=True)\n",
    "                    if not omero_image:\n",
    "                        print(f\"Warning: Image {image_id} not found, skipping\")\n",
    "                        continue\n",
    "                    z_slices = range(omero_image.getSizeZ())\n",
    "                else:\n",
    "                    z_slices = [int(z_slice)]\n",
    "                \n",
    "                # Create empty 3D array to hold all z-slices\n",
    "                img_3d = []\n",
    "                \n",
    "                # Load each z-slice using ezomero.get_image\n",
    "                for z in z_slices:\n",
    "                    z_val = int(z)\n",
    "                    if is_patch and patch_width > 0 and patch_height > 0:\n",
    "                        # Debug start_coords and axis_lengths\n",
    "                        print(f\"  3D Patch Request - start_coords: ({patch_x}, {patch_y}, {z_val}, {channel}, {timepoint}), dimensions: {patch_width}x{patch_height}\")\n",
    "                        \n",
    "                        # Use ezomero.get_image to extract the patch for this z-slice\n",
    "                        _, img_slice = ezomero.get_image(\n",
    "                            conn,\n",
    "                            image_id,\n",
    "                            start_coords=(patch_x, patch_y, z_val, channel, timepoint),\n",
    "                            axis_lengths=(patch_width, patch_height, 1, 1, 1),\n",
    "                            xyzct=True  # Use XYZCT ordering\n",
    "                        )\n",
    "                        \n",
    "                        # Check shape of returned array\n",
    "                        print(f\"  Returned array shape (before extraction): {img_slice.shape}\")\n",
    "                        \n",
    "                        # The result will be 5D, extract just the 2D slice\n",
    "                        img_slice = img_slice[:,:,:, 0, 0]  # Extract the single z-slice\n",
    "                        print(f\"  Extracted slice shape: {img_slice.shape}\")\n",
    "                    else:\n",
    "                        # Get full plane for this z-slice\n",
    "                        _, img_slice = ezomero.get_image(\n",
    "                            conn,\n",
    "                            image_id,\n",
    "                            start_coords=(0, 0, z_val, channel, timepoint),\n",
    "                            axis_lengths=(None, None, 1, 1, 1),\n",
    "                            xyzct=True  # Use XYZCT ordering\n",
    "                        )\n",
    "                        # Check shape of returned array\n",
    "                        print(f\"  Full plane shape (before extraction): {img_slice.shape}\")\n",
    "                        \n",
    "                        # The result will be 5D, extract just the 2D slice\n",
    "                        img_slice = img_slice[0, 0, 0]  # Extract the single z-slice\n",
    "                        print(f\"  Extracted full plane shape: {img_slice.shape}\")\n",
    "                    \n",
    "                    img_3d.append(img_slice)\n",
    "                \n",
    "                # Convert to numpy array\n",
    "                img_3d = np.array(img_3d)\n",
    "                print(f\"  Final 3D array shape: {img_3d.shape}\")\n",
    "                \n",
    "                # Normalize 16-bit to 8-bit\n",
    "                max_val = img_3d.max()\n",
    "                if max_val > 0:\n",
    "                    img_8bit = ((img_3d) * (255.0 / max_val)).astype(np.uint8)\n",
    "                else:\n",
    "                    img_8bit = img_3d.astype(np.uint8)\n",
    "                \n",
    "                # Save as multi-page TIFF for 3D data\n",
    "                output_path = os.path.join(input_dir, f\"input_{n:05d}.tif\")\n",
    "                imwrite(output_path, img_8bit)\n",
    "                print(f\"  Saved 3D TIFF to {output_path} with shape {img_8bit.shape}\")\n",
    "                \n",
    "            else:\n",
    "                # Handle 2D data with patch support using ezomero.get_image\n",
    "                if is_patch and patch_width > 0 and patch_height > 0:\n",
    "                    # Use ezomero.get_image with appropriate coordinates and dimensions\n",
    "                    z_val = z_slice if not isinstance(z_slice, list) else z_slice[0]\n",
    "                    \n",
    "                    # Debug start_coords and axis_lengths\n",
    "                    print(f\"  2D Patch Request - start_coords: ({patch_x}, {patch_y}, {z_val}, {channel}, {timepoint}), dimensions: {patch_width}x{patch_height}\")\n",
    "                    \n",
    "                    _, img_data = ezomero.get_image(\n",
    "                        conn,\n",
    "                        image_id,\n",
    "                        start_coords=(patch_x, patch_y, int(z_val), channel, timepoint),\n",
    "                        axis_lengths=(patch_width, patch_height, 1, 1, 1),\n",
    "                        xyzct=True\n",
    "                    )\n",
    "                    \n",
    "                    # Check shape of returned array\n",
    "                    print(f\"  Returned array shape: {img_data.shape}\")\n",
    "                    \n",
    "                    # The array is already in the right dimensions (width, height, z=1, c=1, t=1)\n",
    "                    # We just need to remove the trailing dimensions\n",
    "                    if len(img_data.shape) == 5:\n",
    "                        # Take only the first (and only) z, c, t indices\n",
    "                        img_data = img_data[:, :, 0, 0, 0]\n",
    "                        # swap x and y dimensions in the numpy array\n",
    "                        img_data = np.swapaxes(img_data, 0, 1)\n",
    "\n",
    "                    \n",
    "                    print(f\"  Extracted 2D shape: {img_data.shape}\")\n",
    "                else:\n",
    "                    # Get full plane\n",
    "                    z_val = z_slice if not isinstance(z_slice, list) else z_slice[0]\n",
    "                    \n",
    "                    # Debug start_coords\n",
    "                    print(f\"  2D Full Image Request - start_coords: (0, 0, {z_val}, {channel}, {timepoint})\")\n",
    "                    \n",
    "                    _, img_data = ezomero.get_image(\n",
    "                        conn,\n",
    "                        image_id,\n",
    "                        start_coords=(0, 0, int(z_val), channel, timepoint),\n",
    "                        axis_lengths=(None, None, 1, 1, 1),\n",
    "                        xyzct=True \n",
    "                    )\n",
    "                    \n",
    "                    # Check shape of returned array \n",
    "                    print(f\"  Returned array shape: {img_data.shape}\")\n",
    "                    \n",
    "                    # Remove trailing dimensions\n",
    "                    if len(img_data.shape) == 5:\n",
    "                        img_data = img_data[:, :, 0, 0, 0]\n",
    "                        img_data = np.swapaxes(img_data, 0, 1)\n",
    "                    \n",
    "                    print(f\"  Extracted 2D shape: {img_data.shape}\")\n",
    "                \n",
    "                # Normalize 16-bit to 8-bit\n",
    "                max_val = img_data.max()\n",
    "                if max_val > 0:\n",
    "                    img_8bit = ((img_data) * (255.0 / max_val)).astype(np.uint8)\n",
    "                else:\n",
    "                    img_8bit = img_data.astype(np.uint8)\n",
    "                \n",
    "                # Save as TIFF\n",
    "                output_path = os.path.join(input_dir, f\"input_{n:05d}.tif\")\n",
    "                imwrite(output_path, img_8bit)\n",
    "                print(f\"  Saved 2D TIFF to {output_path} with shape {img_8bit.shape}\")\n",
    "            \n",
    "            # Get the label file\n",
    "            label_id = int(df.iloc[n]['label_id']) if pd.notna(df.iloc[n]['label_id']) else None\n",
    "            if label_id:\n",
    "                try:\n",
    "                    file_path = ezomero.get_file_annotation(conn, label_id, tmp_dir)\n",
    "                    if file_path:\n",
    "                        label_dest = os.path.join(label_dir, f\"label_{n:05d}.tif\")\n",
    "                        os.rename(file_path, label_dest)\n",
    "                        # Check the size of the saved label\n",
    "                        label_img = imread(label_dest)\n",
    "                        print(f\"  Label shape: {label_img.shape} saved to {label_dest}\")\n",
    "                    else:\n",
    "                        print(f\"  Warning: Label file for image {image_id} not downloaded\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  Error downloading label file: {e}\")\n",
    "            else:\n",
    "                print(f\"  Warning: No label ID for image {image_id}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {subset_type} item {n}: {e}\")\n",
    "    \n",
    "    return input_dir, label_dir\n",
    "\n",
    "# Clean up existing folders\n",
    "folders = [\"training_input\", \"training_label\", \"val_input\", \"val_label\", \"tmp\"]\t\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(output_directory, folder)\n",
    "    if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "        shutil.rmtree(folder_path)\n",
    "\n",
    "# Create tmp directory\n",
    "tmp_dir = os.path.join(output_directory, \"tmp\")\n",
    "os.makedirs(tmp_dir, exist_ok=True)\n",
    "\n",
    "# Prepare training and validation data\n",
    "train_images = table[table['train'] == True]\n",
    "val_images = table[table['validate'] == True]\n",
    "\n",
    "print(f\"Found {len(train_images)} training images and {len(val_images)} validation images\")\n",
    "\n",
    "# Process training data\n",
    "training_input_dir, training_label_dir = prepare_dataset_from_table(\n",
    "    conn, \n",
    "    train_images, \n",
    "    output_directory, \n",
    "    subset_type=\"training\",\n",
    "    tmp_dir=tmp_dir\n",
    ")\n",
    "\n",
    "# Process validation data\n",
    "val_input_dir, val_label_dir = prepare_dataset_from_table(\n",
    "    conn, \n",
    "    val_images, \n",
    "    output_directory, \n",
    "    subset_type=\"val\",\n",
    "    tmp_dir=tmp_dir\n",
    ")\n",
    "\n",
    "print(\"Training data successfully saved to:\", output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data loader for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_patch_shape_from_table(table_df, default_shape=(1, 512, 512), min_size=256):\n",
    "    \"\"\"\n",
    "    Extract optimal patch shape from the OMERO table that contains patch dimensions\n",
    "    \n",
    "    Args:\n",
    "        table_df: DataFrame from OMERO table with patch information\n",
    "        default_shape: Default patch shape to use if no info available (default: (1, 512, 512))\n",
    "        min_size: Minimum acceptable patch dimension (default: 256)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Appropriate patch shape for training (C, H, W)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if we have patch dimensions in the table\n",
    "        if ('patch_width' in table_df.columns and 'patch_height' in table_df.columns and \n",
    "            not table_df['patch_width'].isna().all() and not table_df['patch_height'].isna().all()):\n",
    "            \n",
    "            # Get median patch dimensions from the table (to handle potential variation)\n",
    "            patch_width = int(table_df['patch_width'].median())\n",
    "            patch_height = int(table_df['patch_height'].median())\n",
    "            \n",
    "            # Validate dimensions (must be positive numbers)\n",
    "            if patch_width > 0 and patch_height > 0:\n",
    "                # Apply minimum size constraint\n",
    "                patch_width = max(min_size, patch_width)\n",
    "                patch_height = max(min_size, patch_height)\n",
    "                \n",
    "                # Ensure even dimensions for better compatibility\n",
    "                patch_width = patch_width - (patch_width % 2)\n",
    "                patch_height = patch_height - (patch_height % 2)\n",
    "                \n",
    "                new_shape = (1, patch_height, patch_width)\n",
    "                print(f\"Using patch shape {new_shape} extracted from OMERO table\")\n",
    "                return new_shape\n",
    "            else:\n",
    "                print(f\"Invalid patch dimensions in table: {patch_width}x{patch_height}, using default {default_shape}\")\n",
    "                return default_shape\n",
    "        else:\n",
    "            print(f\"No patch dimensions found in table, using default {default_shape}\")\n",
    "            return default_shape\n",
    "    except Exception as e:\n",
    "        print(f\"Error determining patch shape from table: {e}, using default {default_shape}\")\n",
    "        return default_shape\n",
    "\n",
    "batch_size = 2  # training batch size\n",
    "\n",
    "# Determine patch shape from the OMERO table that contains our annotations\n",
    "patch_shape = determine_patch_shape_from_table(\n",
    "    table,\n",
    "    default_shape=(1, 512, 512),\n",
    "    min_size=256\n",
    ")\n",
    "print(f\"Selected patch shape for training: {patch_shape}\")\n",
    "\n",
    "# Load images from multiple files in folder via pattern (here: all tif files)\n",
    "raw_key, label_key = \"*.tif\", \"*.tif\"\n",
    "\n",
    "# Train an additional convolutional decoder for end-to-end automatic instance segmentation\n",
    "# NOTE 1: It's important to have densely annotated-labels while training the additional convolutional decoder.\n",
    "# NOTE 2: In case you do not have labeled images, we recommend using `micro-sam` annotator tools to annotate as many objects as possible per image for best performance.\n",
    "train_instance_segmentation = True\n",
    "\n",
    "# NOTE: The dataloader internally takes care of adding label transforms: i.e. used to convert the ground-truth\n",
    "# labels to the desired instances for finetuning Segment Anythhing, or, to learn the foreground and distances\n",
    "# to the object centers and object boundaries for automatic segmentation.\n",
    "\n",
    "# There are cases where our inputs are large and the labeled objects are not evenly distributed across the image.\n",
    "# For this we use samplers, which ensure that valid inputs are chosen subjected to the paired labels.\n",
    "# The sampler chosen below makes sure that the chosen inputs have atleast one foreground instance, and filters out small objects.\n",
    "sampler = MinInstanceSampler(min_size=25)  # NOTE: The choice of 'min_size' value is paired with the same value in 'min_size' filter in 'label_transform'.\n",
    "\n",
    "train_loader = sam_training.default_sam_loader(\n",
    "    raw_paths=training_input_dir,\n",
    "    raw_key=raw_key,\n",
    "    label_paths=training_label_dir,\n",
    "    label_key=label_key,\n",
    "    with_segmentation_decoder=train_instance_segmentation,\n",
    "    patch_shape=patch_shape,\n",
    "    batch_size=batch_size,\n",
    "    is_seg_dataset=True,\n",
    "    #rois=train_roi,\n",
    "    shuffle=True,\n",
    "    raw_transform=sam_training.identity,\n",
    "    sampler=sampler,\n",
    ")\n",
    "\n",
    "val_loader = sam_training.default_sam_loader(\n",
    "    raw_paths=val_input_dir,\n",
    "    raw_key=raw_key,\n",
    "    label_paths=val_label_dir,\n",
    "    label_key=label_key,\n",
    "    with_segmentation_decoder=train_instance_segmentation,\n",
    "    patch_shape=patch_shape,\n",
    "    batch_size=batch_size,\n",
    "    is_seg_dataset=True,\n",
    "    #rois=val_roi,\n",
    "    shuffle=True,\n",
    "    raw_transform=sam_training.identity,\n",
    "    sampler=sampler,\n",
    ")\n",
    "check_loader(train_loader, 1, plt=True)\n",
    "check_loader(val_loader, 1, plt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_objects_per_batch = 2  # the number of objects per batch that will be sampled\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # the device/GPU used for training\n",
    "n_epochs = 100  # how long we train (in epochs)\n",
    "print('running on: ', device)\n",
    "# The model_type determines which base model is used to initialize the weights that are finetuned.\n",
    "# We use vit_b here because it can be trained faster. Note that vit_h usually yields higher quality results.\n",
    "model_type = \"vit_l\"\n",
    "\n",
    "# The name of the checkpoint. The checkpoints will be stored in './checkpoints/<checkpoint_name>'\n",
    "checkpoint_name = \"sam\"\n",
    "\n",
    "sam_training.train_sam(\n",
    "    name=checkpoint_name,\n",
    "    save_root=os.path.join(output_directory, \"models\"),\n",
    "    model_type=model_type,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    n_epochs=n_epochs,\n",
    "    #checkpoint_path='C:\\\\Users\\\\mwpaul\\\\micro-sam_models\\\\micro-sam-20250207_095503\\\\models\\\\checkpoints\\\\sam\\\\best.pt', #can be used to train further\n",
    "    n_objects_per_batch=n_objects_per_batch,\n",
    "    with_segmentation_decoder=train_instance_segmentation,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save as bioimage.io model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Union\n",
    "from micro_sam.bioimageio.model_export import export_sam_model\n",
    "\n",
    "# Get a test image and label to use for exporting\n",
    "# For this example, we'll use the first image and label from validation set\n",
    "test_image_path = os.path.join(val_input_dir, os.listdir(val_input_dir)[0])\n",
    "test_label_path = os.path.join(val_label_dir, os.listdir(val_label_dir)[0])\n",
    "\n",
    "# Load the test image and label\n",
    "test_image = np.array(imread(test_image_path))\n",
    "test_label = np.array(imread(test_label_path))\n",
    "\n",
    "# Define the path for saving the bioimage.io model\n",
    "bioimageio_model_path = os.path.join(output_directory, \"bioimage_io_model\")\n",
    "os.makedirs(bioimageio_model_path, exist_ok=True)\n",
    "\n",
    "# Export the SAM model to bioimage.io format\n",
    "export_sam_model(\n",
    "    image=test_image,\n",
    "    label_image=test_label,\n",
    "    model_type=model_type,  # Using the same model_type as in training\n",
    "    name=f\"micro_sam_{timestamp}\",\n",
    "    output_path=bioimageio_model_path,\n",
    "    checkpoint_path=os.path.join(\n",
    "        output_directory, \"models\", \"checkpoints\", checkpoint_name, \"best.pt\"\n",
    "    ),\n",
    "    # Optional: Add additional kwargs as needed\n",
    "    authors=[{\"name\": \"Your Name\", \"affiliation\": \"Your Institution\"}],\n",
    "    description=\"Micro-SAM model trained on microscopy images for segmentation\",\n",
    "    license=\"MIT\",\n",
    "    documentation=\"Model trained with micro-sam for segmenting microscopy images\",\n",
    ")\n",
    "\n",
    "print(f\"BioImage.IO model exported to: {bioimageio_model_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micro-sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
