{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Stardist segmentation on 2D/3D/timelapse OMERO images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used for Stardist segmentation. Some inspiration from the https://github.com/ome/omero-guide-cellprofiler/idr0002.ipynb\n",
    "\n",
    "## TO DO\n",
    "- Make a generic function for 2D segmentation for all slices independent of the shape of the image z,c,t\n",
    "- Include a ID to all files uploaded to OMERO to make it more tracable\n",
    "- Extend to handle multiple channels AND timepoints\n",
    "- Check if we can overwrite label images if nesseary or ROIs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OMERO Python BlitzGateway\n",
    "import omero\n",
    "from omero.gateway import BlitzGateway\n",
    "import ezomero\n",
    "# Import Numpy\n",
    "import numpy as np\n",
    "\n",
    "# Import Python System Packages\n",
    "import os\n",
    "import tempfile\n",
    "import pandas\n",
    "import warnings\n",
    "\n",
    "#stardist related\n",
    "from stardist.models import StarDist2D\n",
    "from csbdeep.utils import normalize\n",
    "from stardist.plot import render_label\n",
    "import matplotlib.pyplot as plt\n",
    "from tifffile import imsave\n",
    "\n",
    "#load stardist model\n",
    "model = StarDist2D.from_pretrained('2D_versatile_fluo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Temp Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "new_output_directory = os.path.normcase(tempfile.mkdtemp())\n",
    "print(new_output_directory)\n",
    "#create unique job id for reference based on date and time\n",
    "job_id = str(datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "print(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup connection with OMERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = BlitzGateway(host='localhost', username='root', passwd='omero', secure=True)\n",
    "print(conn.connect())\n",
    "conn.c.enableKeepAlive(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get info from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = \"dataset\" # \"plate\", \"dataset\", \"image\"\n",
    "data_id = \t502\n",
    "nucl_channel = 0\n",
    "\n",
    "#validate that data_id matches datatype\n",
    "if datatype == \"plate\":\n",
    "    plate = conn.getObject(\"Plate\", data_id)\n",
    "    print('Plate Name: ', plate.getName())\n",
    "elif datatype == \"dataset\":\n",
    "    dataset = conn.getObject(\"Dataset\", data_id)\n",
    "    print('Dataset Name: ', dataset.getName())\n",
    "elif datatype == \"image\":\n",
    "    image = conn.getObject(\"Image\", data_id)\n",
    "    print('Image Name: ', image.getName())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Stardist on the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyclesperanto_prototype as cle\n",
    "import pandas as pd\n",
    "\n",
    "def measure_intensity(pixels, labels, size_z, size_t, size_c):\n",
    "    all_statistics = []\n",
    "    if size_z > 1 and size_t > 1:\n",
    "        #raise error that time series and z-stack data is not supported\n",
    "        raise ValueError(\"Time series and z-stack data is not supported (yet)\")\n",
    "    elif size_t > 1:\n",
    "        for t, label in zip(range(size_t), labels):\n",
    "            for c in range(size_c):\n",
    "                statistics = cle.statistics_of_labelled_pixels(pixels.getPlane(0, c, t), label)\n",
    "                statistics = pd.DataFrame(statistics)\n",
    "                statistics['z'] = 0\n",
    "                statistics['t'] = t\n",
    "                statistics['channel'] = c\n",
    "                all_statistics.append(statistics)   \n",
    "    elif size_z > 1:\n",
    "        for z, label in zip(range(size_z), labels):\n",
    "            for c in range(size_c):\n",
    "                statistics = cle.statistics_of_labelled_pixels(pixels.getPlane(z, c, 0), label)\n",
    "                statistics = pd.DataFrame(statistics)\n",
    "                statistics['z'] = z\n",
    "                statistics['t'] = 0\n",
    "                statistics['channel'] = c\n",
    "                all_statistics.append(statistics)\n",
    "    else:\n",
    "        statistics = cle.statistics_of_labelled_pixels(pixels.getPlane(1, 0, 0), labels)\n",
    "        statistics['z'] = 0\n",
    "        statistics['t'] = t\n",
    "        all_statistics.append(statistics)\n",
    "    \n",
    "    # Concatenate all statistics into a single DataFrame\n",
    "    all_statistics_df = pd.concat(all_statistics, ignore_index=True)\n",
    "    \n",
    "    return all_statistics_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code to run the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import src.ProcessImage as ProcessImage\n",
    "importlib.reload(ProcessImage)\n",
    "\n",
    "#get list of images to process\n",
    "if datatype == \"plate\":\n",
    "    wells = list(plate.listChildren())\n",
    "    well_count = len(wells)\n",
    "    images = []\n",
    "    for count, well in enumerate(wells):\n",
    "        print('Well: %s/%s' % (count + 1, well_count), 'row:', well.row, 'column:', well.column)\n",
    "        # Load all images for a well if there are multiple\n",
    "        fields = well.countWellSample()\n",
    "        for field in range(fields):\n",
    "            print('Field:', field)\n",
    "            image = well.getImage(field)\n",
    "            images.append(image)\n",
    "elif datatype == \"dataset\":\n",
    "    images = list(dataset.listChildren())\n",
    "elif datatype == \"image\":\n",
    "    images = [image]   \n",
    "\n",
    "#process images\n",
    "plate_statistics = []\n",
    "for count,image in enumerate(images):\n",
    "    #save stack back to OMERO same project only add _nucleisegmentation to the name\n",
    "    seg_img_name = image.getName() + \"_nucleisegmentation\"\n",
    "    desc = \"Stardist nuclei segmentation\"\n",
    "    img = ProcessImage.ProcessImage(conn,image,job_id,model)\n",
    "    img.segment_nuclei(nucl_channel)\n",
    "    img.save_segmentation_to_omero_as_attach(new_output_directory,desc)\n",
    "    #img.save_segmentation_to_omero_as_new_image(seg_img_name,desc)\n",
    "    img.save_segmentation_to_omero_as_roi()\n",
    "    all_statistics_df = measure_intensity(img._pixels, img._labels, img._size_z, img._size_t, img._size_c)\n",
    "    all_statistics_df['imageID'] = image.getId()\n",
    "    plate_statistics.append(all_statistics_df)\n",
    "    image_id = image.getId()\n",
    "    tabelid = ezomero.post_table(conn, object_type=\"Image\", object_id=image.getId(), table = all_statistics_df,title=f\"Nuclei_measurements_{job_id}_{image_id}\")\n",
    "    print('Created table ID:', tabelid)\n",
    "# Concatenate all statistics into a single DataFrame\n",
    "plate_statistics_df = pd.concat(plate_statistics, ignore_index=True)\n",
    "tabelid = ezomero.post_table(conn, object_type=\"Dataset\", object_id=data_id, table = plate_statistics_df, title=f\"Nuclei_measurements_{job_id}_{data_id}\")\n",
    "\n",
    "\n",
    "####old code remove asap\n",
    "if datatype == \"plate\":\n",
    "    plate_statistics = []\n",
    "    wells = list(plate.listChildren())\n",
    "    # use the first 3 wells only\n",
    "    wells = wells[0:2] # for testing\n",
    "    well_count = len(wells)\n",
    "    for count, well in enumerate(wells):\n",
    "            print('Well: %s/%s' % (count + 1, well_count), 'row:', well.row, 'column:', well.column)\n",
    "            # Load all images for a well if there are multiple\n",
    "            fields = well.countWellSample()\n",
    "            for field in range(fields):\n",
    "                print('Field:', field)\n",
    "                image = well.getImage(field)\n",
    "                #save stack back to OMERO same project only add _nucleisegmentation to the name\n",
    "                new_img_name = image.getName() + \"_nucleisegmentation\"\n",
    "                desc = \"Stardist nuclei segmentation\"\n",
    "                img = ProcessImage.ProcessImage(image, conn, model)\n",
    "                print('image dimensions:', img._size_z, img._size_c,img._size_t)\n",
    "                img.segment_nuclei(nucl_channel)\n",
    "                img.save_segmentation_to_omero_as_attach(new_output_directory,desc)\n",
    "                #img.save_segmentation_to_omero_as_new_image(new_img_name,desc)\n",
    "                img.save_segmentation_to_omero_as_roi()\n",
    "                all_statistics_df = measure_intensity(img._pixels, img._labels, img._size_z, img._size_t, img._size_c)\n",
    "                all_statistics_df['well'] = well.getId()\n",
    "                plate_statistics.append(all_statistics_df)\n",
    "                tabelid = ezomero.post_table(conn, object_type=\"Image\", object_id=image.getId(), table = all_statistics_df,title=\"Nuclei_measurements\")\n",
    "                print('Created table ID:', tabelid)\n",
    "    # Concatenate all statistics into a single DataFrame\n",
    "    plate_statistics_df = pd.concat(plate_statistics, ignore_index=True)\n",
    "    tabelid = ezomero.post_table(conn, object_type=\"Plate\", object_id=data_id, table = plate_statistics,title=\"Nuclei_measurements\")\n",
    "            \n",
    "elif datatype == \"dataset\":\n",
    "    images = list(dataset.listChildren())\n",
    "    # use the first 3 images only\n",
    "    #images = images[0:3]\n",
    "    image_count = len(images)\n",
    "    plate_statistics = []\n",
    "    for count in range(image_count):\n",
    "        image = images[count]\n",
    "        #save stack back to OMERO same project only add _nucleisegmentation to the name\n",
    "        new_img_name = image.getName() + \"_nucleisegmentation\"\n",
    "        desc = \"Stardist nuclei segmentation\"\n",
    "        img = ProcessImage.ProcessImage(image, conn,model)\n",
    "        img.segment_nuclei(nucl_channel)\n",
    "        img.save_segmentation_to_omero_as_attach(new_output_directory,desc)\n",
    "        #img.save_segmentation_to_omero_as_new_image(desc)\n",
    "        img.save_segmentation_to_omero_as_roi()\n",
    "        all_statistics_df = measure_intensity(img._pixels, img._labels, img._size_z, img._size_t, img._size_c)\n",
    "        all_statistics_df['imageID'] = image.getId()\n",
    "        plate_statistics.append(all_statistics_df)\n",
    "        image_id = image.getId()\n",
    "        tabelid = ezomero.post_table(conn, object_type=\"Image\", object_id=image.getId(), table = all_statistics_df,title=f\"Nuclei_measurements_{job_id}_{image_id}\")\n",
    "        print('Created table ID:', tabelid)\n",
    "    # Concatenate all statistics into a single DataFrame\n",
    "    plate_statistics_df = pd.concat(plate_statistics, ignore_index=True)\n",
    "    tabelid = ezomero.post_table(conn, object_type=\"Dataset\", object_id=data_id, table = plate_statistics_df, title=f\"Nuclei_measurements_{job_id}_{data_id}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete attachements from project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = \"dataset\" # \"plate\", \"dataset\", \"image\"\n",
    "data_id = \t502\n",
    "\n",
    "def ensure_list(obj):\n",
    "    if not obj:\n",
    "        return []\n",
    "    if isinstance(obj, list):\n",
    "        return obj\n",
    "    return [obj]\n",
    "\n",
    "if datatype == \"dataset\":\n",
    "    images = list(dataset.listChildren())\n",
    "    image_count = len(images)\n",
    "    plate_statistics = []\n",
    "    to_delete = []\n",
    "    for count in range(image_count):\n",
    "        image = images[count]\n",
    "        i = conn.getObject(\"Image\", image.getId())\n",
    "        print('Image Name:', i.getName())\n",
    "        \n",
    "        for ann in i.listAnnotations():\n",
    "            link_id = ann.link.id  # sometimes single, sometimes list\n",
    "            link_ids = ensure_list(link_id)\n",
    "\n",
    "            for lid in link_ids:\n",
    "                to_delete.append(lid)\n",
    "    conn.deleteObjects(\"ImageAnnotationLink\", to_delete, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete ROIs from project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = \"dataset\" # \"plate\", \"dataset\", \"image\"\n",
    "data_id = \t502\n",
    "\n",
    "if datatype == \"dataset\":\n",
    "    images = list(dataset.listChildren())\n",
    "    image_count = len(images)\n",
    "    plate_statistics = []\n",
    "    for count in range(image_count):\n",
    "        image = images[count]\n",
    "        roi_service = conn.getRoiService()\n",
    "        result = roi_service.findByImage(image.getId(), None)\n",
    "        roi_ids = [roi.id.val for roi in result.rois]\n",
    "        conn.deleteObjects(\"Roi\", roi_ids)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omero-guide-cellprofiler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
